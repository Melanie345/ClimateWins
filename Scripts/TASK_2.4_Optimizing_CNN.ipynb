{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fa2e0c-edb1-44e8-95f2-248b5599669d",
   "metadata": {},
   "source": [
    "# TASK 2.4 Optimizing CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6412e42-c64b-439c-a059-0291eb3dbc73",
   "metadata": {},
   "source": [
    "#### Importing libraries and data\n",
    "#### Import unscaled data and pleasant weather sets\n",
    "#### Data wrangling\n",
    "#### Reshaping for modeling\n",
    "#### Data Split\n",
    "#### Hyperparameter Optimization - Bayesian\n",
    "#### Run CNN with Optimized Search Parameters\n",
    "#### Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766a4a2-9a9b-4d2a-bb80-767f02bacdf6",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf90e7f-d903-4a8c-b0d7-1709ab94d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports are successful! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(\"All imports are successful! ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b734df0d-a1bc-4fff-8ab1-425cb5a9f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique, reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Initialize LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403a1055-4424-4a86-ab08-f4086729f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define path\n",
    "path = r'C:\\Users\\melan\\OneDrive\\Career Foundry\\Machine Learning with Python\\Data Sets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5cb553-d390-436c-aaae-ab52e80c5ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\melan\\\\OneDrive\\\\Career Foundry\\\\Machine Learning with Python\\\\Data Sets'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35443c25-bd50-4a9f-a3e1-65c5fd181086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import unscaled data\n",
    "X = pd.read_csv(os.path.join(path, 'unscaled_withdate.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ee25e00-65c0-43fd-9f95-c9e31357abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pleasant weather answers csv file\n",
    "pleasant_weather = pd.read_csv(os.path.join(path,'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "117b032c-a854-4526-b7b4-21c60ecbedb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>BELGRADE_humidity</th>\n",
       "      <th>BELGRADE_pressure</th>\n",
       "      <th>BELGRADE_global_radiation</th>\n",
       "      <th>BELGRADE_precipitation</th>\n",
       "      <th>BELGRADE_sunshine</th>\n",
       "      <th>BELGRADE_temp_mean</th>\n",
       "      <th>BELGRADE_temp_min</th>\n",
       "      <th>BELGRADE_temp_max</th>\n",
       "      <th>BUDAPEST_cloud_cover</th>\n",
       "      <th>BUDAPEST_humidity</th>\n",
       "      <th>BUDAPEST_pressure</th>\n",
       "      <th>BUDAPEST_global_radiation</th>\n",
       "      <th>BUDAPEST_precipitation</th>\n",
       "      <th>BUDAPEST_sunshine</th>\n",
       "      <th>BUDAPEST_temp_mean</th>\n",
       "      <th>BUDAPEST_temp_min</th>\n",
       "      <th>BUDAPEST_temp_max</th>\n",
       "      <th>DEBILT_cloud_cover</th>\n",
       "      <th>DEBILT_humidity</th>\n",
       "      <th>DEBILT_pressure</th>\n",
       "      <th>DEBILT_global_radiation</th>\n",
       "      <th>DEBILT_precipitation</th>\n",
       "      <th>DEBILT_sunshine</th>\n",
       "      <th>DEBILT_temp_mean</th>\n",
       "      <th>DEBILT_temp_min</th>\n",
       "      <th>DEBILT_temp_max</th>\n",
       "      <th>DUSSELDORF_cloud_cover</th>\n",
       "      <th>DUSSELDORF_humidity</th>\n",
       "      <th>DUSSELDORF_pressure</th>\n",
       "      <th>DUSSELDORF_global_radiation</th>\n",
       "      <th>DUSSELDORF_precipitation</th>\n",
       "      <th>DUSSELDORF_sunshine</th>\n",
       "      <th>DUSSELDORF_temp_mean</th>\n",
       "      <th>DUSSELDORF_temp_min</th>\n",
       "      <th>DUSSELDORF_temp_max</th>\n",
       "      <th>HEATHROW_cloud_cover</th>\n",
       "      <th>HEATHROW_humidity</th>\n",
       "      <th>HEATHROW_pressure</th>\n",
       "      <th>HEATHROW_global_radiation</th>\n",
       "      <th>HEATHROW_precipitation</th>\n",
       "      <th>HEATHROW_sunshine</th>\n",
       "      <th>HEATHROW_temp_mean</th>\n",
       "      <th>HEATHROW_temp_min</th>\n",
       "      <th>HEATHROW_temp_max</th>\n",
       "      <th>KASSEL_humidity</th>\n",
       "      <th>KASSEL_pressure</th>\n",
       "      <th>KASSEL_global_radiation</th>\n",
       "      <th>KASSEL_precipitation</th>\n",
       "      <th>KASSEL_sunshine</th>\n",
       "      <th>KASSEL_temp_mean</th>\n",
       "      <th>KASSEL_temp_min</th>\n",
       "      <th>KASSEL_temp_max</th>\n",
       "      <th>LJUBLJANA_cloud_cover</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>LJUBLJANA_humidity</th>\n",
       "      <th>LJUBLJANA_pressure</th>\n",
       "      <th>LJUBLJANA_global_radiation</th>\n",
       "      <th>LJUBLJANA_precipitation</th>\n",
       "      <th>LJUBLJANA_sunshine</th>\n",
       "      <th>LJUBLJANA_temp_mean</th>\n",
       "      <th>LJUBLJANA_temp_min</th>\n",
       "      <th>LJUBLJANA_temp_max</th>\n",
       "      <th>MAASTRICHT_cloud_cover</th>\n",
       "      <th>MAASTRICHT_humidity</th>\n",
       "      <th>MAASTRICHT_pressure</th>\n",
       "      <th>MAASTRICHT_global_radiation</th>\n",
       "      <th>MAASTRICHT_precipitation</th>\n",
       "      <th>MAASTRICHT_sunshine</th>\n",
       "      <th>MAASTRICHT_temp_mean</th>\n",
       "      <th>MAASTRICHT_temp_min</th>\n",
       "      <th>MAASTRICHT_temp_max</th>\n",
       "      <th>MADRID_cloud_cover</th>\n",
       "      <th>MADRID_humidity</th>\n",
       "      <th>MADRID_pressure</th>\n",
       "      <th>MADRID_global_radiation</th>\n",
       "      <th>MADRID_precipitation</th>\n",
       "      <th>MADRID_sunshine</th>\n",
       "      <th>MADRID_temp_mean</th>\n",
       "      <th>MADRID_temp_min</th>\n",
       "      <th>MADRID_temp_max</th>\n",
       "      <th>MUNCHENB_cloud_cover</th>\n",
       "      <th>MUNCHENB_humidity</th>\n",
       "      <th>MUNCHENB_global_radiation</th>\n",
       "      <th>MUNCHENB_precipitation</th>\n",
       "      <th>MUNCHENB_sunshine</th>\n",
       "      <th>MUNCHENB_temp_mean</th>\n",
       "      <th>MUNCHENB_temp_min</th>\n",
       "      <th>MUNCHENB_temp_max</th>\n",
       "      <th>OSLO_cloud_cover</th>\n",
       "      <th>OSLO_humidity</th>\n",
       "      <th>OSLO_pressure</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "      <th>OSLO_global_radiation</th>\n",
       "      <th>OSLO_precipitation</th>\n",
       "      <th>OSLO_sunshine</th>\n",
       "      <th>OSLO_temp_mean</th>\n",
       "      <th>OSLO_temp_min</th>\n",
       "      <th>OSLO_temp_max</th>\n",
       "      <th>SONNBLICK_cloud_cover</th>\n",
       "      <th>SONNBLICK_humidity</th>\n",
       "      <th>SONNBLICK_pressure</th>\n",
       "      <th>SONNBLICK_global_radiation</th>\n",
       "      <th>SONNBLICK_precipitation</th>\n",
       "      <th>MUNCHENB_pressure</th>\n",
       "      <th>SONNBLICK_sunshine</th>\n",
       "      <th>SONNBLICK_temp_mean</th>\n",
       "      <th>SONNBLICK_temp_min</th>\n",
       "      <th>SONNBLICK_temp_max</th>\n",
       "      <th>STOCKHOLM_cloud_cover</th>\n",
       "      <th>STOCKHOLM_pressure</th>\n",
       "      <th>STOCKHOLM_global_radiation</th>\n",
       "      <th>STOCKHOLM_precipitation</th>\n",
       "      <th>STOCKHOLM_sunshine</th>\n",
       "      <th>STOCKHOLM_temp_mean</th>\n",
       "      <th>STOCKHOLM_temp_min</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0195</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0032</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0063</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0172</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0062</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0179</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0165</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0166</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0234</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0244</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0262</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0269</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0092</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  MONTH  BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
       "0  19600101      1                  7            0.85           1.018   \n",
       "1  19600102      1                  6            0.84           1.018   \n",
       "2  19600103      1                  8            0.90           1.018   \n",
       "3  19600104      1                  3            0.92           1.018   \n",
       "4  19600105      1                  6            0.95           1.018   \n",
       "\n",
       "   BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
       "0                    0.32                 0.09             0.7   \n",
       "1                    0.36                 1.05             1.1   \n",
       "2                    0.18                 0.30             0.0   \n",
       "3                    0.58                 0.00             4.1   \n",
       "4                    0.65                 0.14             5.4   \n",
       "\n",
       "   BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  BELGRADE_cloud_cover  \\\n",
       "0              6.5             0.8            10.9                     1   \n",
       "1              6.1             3.3            10.1                     6   \n",
       "2              8.5             5.1             9.9                     6   \n",
       "3              6.3             3.8            10.6                     8   \n",
       "4              3.0            -0.7             6.0                     8   \n",
       "\n",
       "   BELGRADE_humidity  BELGRADE_pressure  BELGRADE_global_radiation  \\\n",
       "0               0.81             1.0195                       0.88   \n",
       "1               0.84             1.0172                       0.25   \n",
       "2               0.77             1.0179                       0.67   \n",
       "3               0.93             1.0268                       0.25   \n",
       "4               0.99             1.0286                       0.25   \n",
       "\n",
       "   BELGRADE_precipitation  BELGRADE_sunshine  BELGRADE_temp_mean  \\\n",
       "0                    0.00                7.0                 3.7   \n",
       "1                    0.00                0.0                 2.9   \n",
       "2                    0.00                3.5                 3.1   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.06                0.0                 2.0   \n",
       "\n",
       "   BELGRADE_temp_min  BELGRADE_temp_max  BUDAPEST_cloud_cover  \\\n",
       "0               -0.9                7.9                     4   \n",
       "1                2.2                4.4                     4   \n",
       "2               -0.5                6.4                     4   \n",
       "3               -2.0                3.0                     4   \n",
       "4                0.7                2.8                     4   \n",
       "\n",
       "   BUDAPEST_humidity  BUDAPEST_pressure  BUDAPEST_global_radiation  \\\n",
       "0               0.67              1.017                       0.44   \n",
       "1               0.67              1.017                       0.18   \n",
       "2               0.67              1.017                       0.30   \n",
       "3               0.67              1.017                       0.19   \n",
       "4               0.67              1.017                       0.19   \n",
       "\n",
       "   BUDAPEST_precipitation  BUDAPEST_sunshine  BUDAPEST_temp_mean  \\\n",
       "0                    0.01                2.3                 2.4   \n",
       "1                    0.31                0.0                 2.3   \n",
       "2                    0.00                0.6                 2.7   \n",
       "3                    0.00                0.0                 2.0   \n",
       "4                    0.00                0.0                 2.5   \n",
       "\n",
       "   BUDAPEST_temp_min  BUDAPEST_temp_max  DEBILT_cloud_cover  DEBILT_humidity  \\\n",
       "0               -0.4                5.1                   7             0.85   \n",
       "1                1.4                3.1                   8             0.90   \n",
       "2                1.7                5.3                   6             0.92   \n",
       "3                0.4                4.4                   8             0.95   \n",
       "4                1.1                5.3                   6             0.90   \n",
       "\n",
       "   DEBILT_pressure  DEBILT_global_radiation  DEBILT_precipitation  \\\n",
       "0           1.0032                     0.07                  0.25   \n",
       "1           1.0056                     0.14                  0.06   \n",
       "2           1.0165                     0.28                  0.01   \n",
       "3           1.0265                     0.08                  0.09   \n",
       "4           1.0243                     0.04                  0.39   \n",
       "\n",
       "   DEBILT_sunshine  DEBILT_temp_mean  DEBILT_temp_min  DEBILT_temp_max  \\\n",
       "0              0.0               9.3              7.4             11.0   \n",
       "1              0.1               7.7              6.4              8.3   \n",
       "2              3.0               6.8              4.6              9.9   \n",
       "3              0.0               6.7              3.6             10.1   \n",
       "4              0.0               8.0              2.4             11.2   \n",
       "\n",
       "   DUSSELDORF_cloud_cover  DUSSELDORF_humidity  DUSSELDORF_pressure  \\\n",
       "0                       8                 0.83               1.0161   \n",
       "1                       8                 0.89               1.0161   \n",
       "2                       7                 0.95               1.0161   \n",
       "3                       8                 0.86               1.0161   \n",
       "4                       7                 0.92               1.0161   \n",
       "\n",
       "   DUSSELDORF_global_radiation  DUSSELDORF_precipitation  DUSSELDORF_sunshine  \\\n",
       "0                         0.12                      0.08                  0.0   \n",
       "1                         0.18                      0.66                  0.5   \n",
       "2                         0.12                      0.07                  0.0   \n",
       "3                         0.12                      0.02                  0.0   \n",
       "4                         0.12                      0.62                  0.0   \n",
       "\n",
       "   DUSSELDORF_temp_mean  DUSSELDORF_temp_min  DUSSELDORF_temp_max  \\\n",
       "0                  10.0                  7.0                 11.5   \n",
       "1                   8.2                  7.4                 11.0   \n",
       "2                   7.1                  6.9                  9.1   \n",
       "3                   6.8                  3.6                  8.0   \n",
       "4                   7.7                  6.2                 11.0   \n",
       "\n",
       "   HEATHROW_cloud_cover  HEATHROW_humidity  HEATHROW_pressure  \\\n",
       "0                     7               0.91             1.0010   \n",
       "1                     7               0.98             1.0051   \n",
       "2                     8               0.96             1.0166   \n",
       "3                     8               0.98             1.0230   \n",
       "4                     5               0.84             1.0275   \n",
       "\n",
       "   HEATHROW_global_radiation  HEATHROW_precipitation  HEATHROW_sunshine  \\\n",
       "0                       0.13                    0.22                0.0   \n",
       "1                       0.13                    0.23                0.0   \n",
       "2                       0.15                    0.07                0.1   \n",
       "3                       0.13                    0.00                0.0   \n",
       "4                       0.30                    0.00                2.1   \n",
       "\n",
       "   HEATHROW_temp_mean  HEATHROW_temp_min  HEATHROW_temp_max  KASSEL_humidity  \\\n",
       "0                10.6                9.4                8.3             0.82   \n",
       "1                 6.1                3.9               10.6             0.86   \n",
       "2                 8.4                6.1               12.2             0.91   \n",
       "3                 9.4                6.7                8.9             0.87   \n",
       "4                 8.9                8.9                7.2             0.86   \n",
       "\n",
       "   KASSEL_pressure  KASSEL_global_radiation  KASSEL_precipitation  \\\n",
       "0           1.0094                     0.28                  0.48   \n",
       "1           1.0086                     0.12                  0.27   \n",
       "2           1.0129                     0.12                  0.60   \n",
       "3           1.0290                     0.12                  0.00   \n",
       "4           1.0262                     0.13                  0.71   \n",
       "\n",
       "   KASSEL_sunshine  KASSEL_temp_mean  KASSEL_temp_min  KASSEL_temp_max  \\\n",
       "0              1.6               7.9              3.9              9.4   \n",
       "1              0.0               7.7              6.8              9.1   \n",
       "2              0.0               6.5              6.0              8.0   \n",
       "3              0.0               5.8              5.2              6.5   \n",
       "4              0.0               5.4              3.7              6.0   \n",
       "\n",
       "   LJUBLJANA_cloud_cover  KASSEL_cloud_cover  LJUBLJANA_humidity  \\\n",
       "0                      8                   8                1.00   \n",
       "1                      6                   6                0.94   \n",
       "2                      8                   8                0.96   \n",
       "3                      6                   6                0.94   \n",
       "4                      7                   7                0.94   \n",
       "\n",
       "   LJUBLJANA_pressure  LJUBLJANA_global_radiation  LJUBLJANA_precipitation  \\\n",
       "0              1.0173                        0.20                     0.00   \n",
       "1              1.0173                        0.56                     0.13   \n",
       "2              1.0173                        0.20                     0.12   \n",
       "3              1.0173                        0.49                     0.00   \n",
       "4              1.0173                        0.20                     0.00   \n",
       "\n",
       "   LJUBLJANA_sunshine  LJUBLJANA_temp_mean  LJUBLJANA_temp_min  \\\n",
       "0                 0.0                 -0.6                -1.9   \n",
       "1                 3.2                  2.1                -1.3   \n",
       "2                 0.0                  4.6                 0.9   \n",
       "3                 2.2                  3.2                 1.0   \n",
       "4                 0.0                  3.6                 0.4   \n",
       "\n",
       "   LJUBLJANA_temp_max  MAASTRICHT_cloud_cover  MAASTRICHT_humidity  \\\n",
       "0                 0.5                       7                 0.83   \n",
       "1                 5.5                       8                 0.92   \n",
       "2                 6.3                       7                 0.97   \n",
       "3                 7.0                       7                 0.89   \n",
       "4                 4.8                       7                 0.92   \n",
       "\n",
       "   MAASTRICHT_pressure  MAASTRICHT_global_radiation  MAASTRICHT_precipitation  \\\n",
       "0               1.0063                         0.22                      0.32   \n",
       "1               1.0062                         0.17                      1.34   \n",
       "2               1.0167                         0.12                      0.46   \n",
       "3               1.0277                         0.16                      0.00   \n",
       "4               1.0259                         0.12                      0.56   \n",
       "\n",
       "   MAASTRICHT_sunshine  MAASTRICHT_temp_mean  MAASTRICHT_temp_min  \\\n",
       "0                  1.0                   9.5                  8.5   \n",
       "1                  0.4                   8.6                  7.5   \n",
       "2                  0.0                   6.9                  5.5   \n",
       "3                  0.3                   7.0                  3.0   \n",
       "4                  0.0                   8.1                  2.5   \n",
       "\n",
       "   MAASTRICHT_temp_max  MADRID_cloud_cover  MADRID_humidity  MADRID_pressure  \\\n",
       "0                 11.1                   6             0.92           1.0260   \n",
       "1                  9.9                   7             0.86           1.0254   \n",
       "2                  9.9                   5             0.90           1.0287   \n",
       "3                 10.0                   0             0.75           1.0281   \n",
       "4                 11.1                   2             0.64           1.0269   \n",
       "\n",
       "   MADRID_global_radiation  MADRID_precipitation  MADRID_sunshine  \\\n",
       "0                     0.53                   0.0              1.4   \n",
       "1                     0.46                   0.0              0.9   \n",
       "2                     0.63                   0.0              2.3   \n",
       "3                     1.16                   0.0              8.7   \n",
       "4                     1.10                   0.0              7.8   \n",
       "\n",
       "   MADRID_temp_mean  MADRID_temp_min  MADRID_temp_max  MUNCHENB_cloud_cover  \\\n",
       "0               7.6              4.4             10.8                     5   \n",
       "1               9.8              7.4             12.2                     6   \n",
       "2               8.6              6.4             10.8                     6   \n",
       "3              10.3              4.5             16.1                     6   \n",
       "4              12.1              8.2             16.0                     5   \n",
       "\n",
       "   MUNCHENB_humidity  MUNCHENB_global_radiation  MUNCHENB_precipitation  \\\n",
       "0               0.67                       0.20                    0.10   \n",
       "1               0.72                       0.61                    0.30   \n",
       "2               0.91                       0.20                    0.30   \n",
       "3               0.90                       0.20                    0.01   \n",
       "4               0.85                       0.65                    0.96   \n",
       "\n",
       "   MUNCHENB_sunshine  MUNCHENB_temp_mean  MUNCHENB_temp_min  \\\n",
       "0                0.0                 6.9                1.1   \n",
       "1                5.1                 6.2                4.2   \n",
       "2                0.0                 5.8                4.0   \n",
       "3                0.0                 3.9                3.2   \n",
       "4                5.6                 1.8               -3.0   \n",
       "\n",
       "   MUNCHENB_temp_max  OSLO_cloud_cover  OSLO_humidity  OSLO_pressure  \\\n",
       "0               10.4                 8           0.98         0.9978   \n",
       "1               10.2                 8           0.62         1.0139   \n",
       "2                8.0                 8           0.69         1.0234   \n",
       "3                5.4                 8           0.98         1.0244   \n",
       "4                6.0                 8           0.96         1.0092   \n",
       "\n",
       "   STOCKHOLM_humidity  OSLO_global_radiation  OSLO_precipitation  \\\n",
       "0                0.98                   0.04                1.14   \n",
       "1                0.62                   0.04                0.00   \n",
       "2                0.69                   0.04                0.08   \n",
       "3                0.98                   0.04                0.35   \n",
       "4                0.96                   0.05                0.26   \n",
       "\n",
       "   OSLO_sunshine  OSLO_temp_mean  OSLO_temp_min  OSLO_temp_max  \\\n",
       "0            0.0             4.9            3.8            5.9   \n",
       "1            0.0             3.4            2.8            4.9   \n",
       "2            0.0             1.9            0.6            3.1   \n",
       "3            0.0             3.0            0.4            4.9   \n",
       "4            0.0             3.7            2.9            4.9   \n",
       "\n",
       "   SONNBLICK_cloud_cover  SONNBLICK_humidity  SONNBLICK_pressure  \\\n",
       "0                      4                0.73              1.0304   \n",
       "1                      6                0.97              1.0292   \n",
       "2                      8                0.93              1.0320   \n",
       "3                      5                0.93              1.0443   \n",
       "4                      2                0.75              1.0430   \n",
       "\n",
       "   SONNBLICK_global_radiation  SONNBLICK_precipitation  MUNCHENB_pressure  \\\n",
       "0                        0.48                     0.01             1.0304   \n",
       "1                        0.21                     0.61             1.0292   \n",
       "2                        0.21                     3.20             1.0320   \n",
       "3                        0.22                     1.10             1.0443   \n",
       "4                        0.72                     0.01             1.0430   \n",
       "\n",
       "   SONNBLICK_sunshine  SONNBLICK_temp_mean  SONNBLICK_temp_min  \\\n",
       "0                 2.3                 -5.9                -8.5   \n",
       "1                 0.0                 -9.5               -10.5   \n",
       "2                 0.0                 -9.5               -10.0   \n",
       "3                 0.0                -11.5               -12.9   \n",
       "4                 6.1                 -9.3               -12.0   \n",
       "\n",
       "   SONNBLICK_temp_max  STOCKHOLM_cloud_cover  STOCKHOLM_pressure  \\\n",
       "0                -3.2                      5              1.0114   \n",
       "1                -8.5                      5              1.0114   \n",
       "2                -8.9                      5              1.0114   \n",
       "3               -10.0                      5              1.0114   \n",
       "4                -6.5                      5              1.0114   \n",
       "\n",
       "   STOCKHOLM_global_radiation  STOCKHOLM_precipitation  STOCKHOLM_sunshine  \\\n",
       "0                        0.05                     0.32                 0.0   \n",
       "1                        0.05                     0.06                 0.0   \n",
       "2                        0.05                     0.02                 0.0   \n",
       "3                        0.05                     0.00                 0.0   \n",
       "4                        0.05                     1.32                 0.0   \n",
       "\n",
       "   STOCKHOLM_temp_mean  STOCKHOLM_temp_min  STOCKHOLM_temp_max  \\\n",
       "0                  4.2                 2.2                 4.9   \n",
       "1                  4.0                 3.0                 5.0   \n",
       "2                  2.4                 1.3                 4.1   \n",
       "3                  1.2                 0.4                 2.3   \n",
       "4                  3.3                 0.8                 4.3   \n",
       "\n",
       "   VALENTIA_cloud_cover  VALENTIA_humidity  VALENTIA_pressure  \\\n",
       "0                     5               0.88             1.0003   \n",
       "1                     7               0.91             1.0007   \n",
       "2                     7               0.91             1.0096   \n",
       "3                     7               0.86             1.0184   \n",
       "4                     3               0.80             1.0328   \n",
       "\n",
       "   VALENTIA_global_radiation  VALENTIA_precipitation  VALENTIA_sunshine  \\\n",
       "0                       0.45                    0.34                4.7   \n",
       "1                       0.25                    0.84                0.7   \n",
       "2                       0.17                    0.08                0.1   \n",
       "3                       0.13                    0.98                0.0   \n",
       "4                       0.46                    0.00                5.7   \n",
       "\n",
       "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                 8.5                6.0               10.9  \n",
       "1                 8.9                5.6               12.1  \n",
       "2                10.5                8.1               12.9  \n",
       "3                 7.4                7.3               10.6  \n",
       "4                 5.7                3.0                8.4  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "802af3ce-c265-455d-ae00-0ce77040acd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 137)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09708b29-7840-41a8-b2db-21cca5642a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0  19600101                       0                          0   \n",
       "1  19600102                       0                          0   \n",
       "2  19600103                       0                          0   \n",
       "3  19600104                       0                          0   \n",
       "4  19600105                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c4b4814-f0ed-4f20-8a6c-bb53b3474411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b40118-b61a-451d-87cd-98d5fd5cd54a",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee3e93cd-0d1d-4ed5-abab-ec5db8604438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "X.drop(['DATE', 'MONTH'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6767e82d-8c6e-4926-9f73-3ac4c7a5ab3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "581ce440-4d10-4f89-94b6-ee018a547e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant_weather.drop(columns = 'DATE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91ec1541-1e96-4cf4-a033-d6fcc0a2b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf7283-ffdf-451a-9e65-1b87958228a0",
   "metadata": {},
   "source": [
    "## Reshaping for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a96e2-bb36-4d20-8aa1-dab05c9e861e",
   "metadata": {},
   "source": [
    "##### Ensure the layers can be fed to the deep learning model correctly\n",
    "##### The final shapes should be X = (22950, 15, 9) and y = (22950,)\n",
    "##### Use the argmax function to transform the y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ed91574-d6ac-4540-a341-4a4a43fbbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn X and pleasant_weather from dataframe to arrays\n",
    "X = np.array (X)\n",
    "y = np.array(pleasant_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5930fb5b-0e53-49f1-bf30-86408cdc60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a6671e1-8729-459a-9282-00241d8ddbf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape/array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "654c0746-8a3b-44c8-b8f0-2244c398f3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using argmax to transform y\n",
    "y = np.argmax(y, axis = 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7c77e2c-e3c3-4ca5-b100-546e98093cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43114341-6a4e-4447-97a9-8bdf08945564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the y layout Code Snippet 1\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1075b4-2321-43e5-bb6f-ef64f674f232",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8388e0c8-655e-4c81-99af-7ec0a0574210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e94a77b-06ea-48d5-8ec9-16ec4047a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17212, 15, 9) (17212,)\n",
      "(5738, 15, 9) (5738,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c19eb-5f2c-4587-b852-b8c973329bed",
   "metadata": {},
   "source": [
    "### Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "05c0c696-1d98-4457-8107-937cca6362fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 # of weather stations)\n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd6cd043-72e9-4b94-baa1-8074c6fa8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "                 'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "                 'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "                 'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "972eba88-3357-4c16-8187-a85a8d346e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/32\n",
      "15/15 - 5s - 337ms/step - accuracy: 0.3947 - loss: 38.1710\n",
      "Epoch 2/32\n",
      "15/15 - 1s - 78ms/step - accuracy: 0.4589 - loss: 35.5049\n",
      "Epoch 3/32\n",
      "15/15 - 1s - 87ms/step - accuracy: 0.4923 - loss: 26.1755\n",
      "Epoch 4/32\n",
      "15/15 - 1s - 55ms/step - accuracy: 0.5050 - loss: 22.4248\n",
      "Epoch 5/32\n",
      "15/15 - 1s - 56ms/step - accuracy: 0.4908 - loss: 21.7140\n",
      "Epoch 6/32\n",
      "15/15 - 1s - 58ms/step - accuracy: 0.5061 - loss: 15.8993\n",
      "Epoch 7/32\n",
      "15/15 - 1s - 51ms/step - accuracy: 0.5300 - loss: 12.9148\n",
      "Epoch 8/32\n",
      "15/15 - 1s - 40ms/step - accuracy: 0.4851 - loss: 15.9632\n",
      "Epoch 9/32\n",
      "15/15 - 1s - 39ms/step - accuracy: 0.5242 - loss: 9.8326\n",
      "Epoch 10/32\n",
      "15/15 - 1s - 51ms/step - accuracy: 0.5195 - loss: 8.8023\n",
      "Epoch 11/32\n",
      "15/15 - 1s - 88ms/step - accuracy: 0.5409 - loss: 6.7206\n",
      "Epoch 12/32\n",
      "15/15 - 1s - 54ms/step - accuracy: 0.5419 - loss: 7.0807\n",
      "Epoch 13/32\n",
      "15/15 - 1s - 49ms/step - accuracy: 0.5491 - loss: 5.8682\n",
      "Epoch 14/32\n",
      "15/15 - 1s - 38ms/step - accuracy: 0.5446 - loss: 5.1030\n",
      "Epoch 15/32\n",
      "15/15 - 1s - 40ms/step - accuracy: 0.5491 - loss: 4.4263\n",
      "Epoch 16/32\n",
      "15/15 - 1s - 36ms/step - accuracy: 0.5414 - loss: 4.6888\n",
      "Epoch 17/32\n",
      "15/15 - 1s - 45ms/step - accuracy: 0.5622 - loss: 3.8310\n",
      "Epoch 18/32\n",
      "15/15 - 0s - 33ms/step - accuracy: 0.5537 - loss: 3.4603\n",
      "Epoch 19/32\n",
      "15/15 - 1s - 40ms/step - accuracy: 0.5650 - loss: 3.0576\n",
      "Epoch 20/32\n",
      "15/15 - 1s - 42ms/step - accuracy: 0.5600 - loss: 2.8543\n",
      "Epoch 21/32\n",
      "15/15 - 1s - 51ms/step - accuracy: 0.5380 - loss: 3.4107\n",
      "Epoch 22/32\n",
      "15/15 - 1s - 53ms/step - accuracy: 0.5727 - loss: 2.7821\n",
      "Epoch 23/32\n",
      "15/15 - 1s - 48ms/step - accuracy: 0.5440 - loss: 3.3902\n",
      "Epoch 24/32\n",
      "15/15 - 1s - 56ms/step - accuracy: 0.5740 - loss: 2.4844\n",
      "Epoch 25/32\n",
      "15/15 - 1s - 83ms/step - accuracy: 0.5508 - loss: 2.7739\n",
      "Epoch 26/32\n",
      "15/15 - 1s - 58ms/step - accuracy: 0.5666 - loss: 2.6888\n",
      "Epoch 27/32\n",
      "15/15 - 1s - 50ms/step - accuracy: 0.5524 - loss: 2.8863\n",
      "Epoch 28/32\n",
      "15/15 - 1s - 57ms/step - accuracy: 0.5788 - loss: 2.2455\n",
      "Epoch 29/32\n",
      "15/15 - 1s - 43ms/step - accuracy: 0.5700 - loss: 2.2602\n",
      "Epoch 30/32\n",
      "15/15 - 1s - 41ms/step - accuracy: 0.5987 - loss: 1.9807\n",
      "Epoch 31/32\n",
      "15/15 - 1s - 47ms/step - accuracy: 0.5821 - loss: 2.2830\n",
      "Epoch 32/32\n",
      "15/15 - 1s - 44ms/step - accuracy: 0.5735 - loss: 2.2419\n",
      "4/4 - 0s - 97ms/step\n",
      "Epoch 1/32\n",
      "Epoch 1/32\n",
      "Epoch 1/32\n",
      "Epoch 1/32\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m3.371    \u001b[39m | \u001b[39m960.6    \u001b[39m | \u001b[39m0.732    \u001b[39m | \u001b[39m0.1796   \u001b[39m | \u001b[39m32.48    \u001b[39m | \u001b[39m1.312    \u001b[39m | \u001b[39m1.116    \u001b[39m | \u001b[39m2.732    \u001b[39m | \u001b[39m0.6051   \u001b[39m | \u001b[39m73.73    \u001b[39m | \u001b[39m0.02058  \u001b[39m | \u001b[39m6.789    \u001b[39m |\n",
      "Epoch 1/44\n",
      "38/38 - 4s - 97ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/44\n",
      "38/38 - 1s - 15ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/44\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/44\n",
      "38/38 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/44\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/44\n",
      "38/38 - 1s - 15ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/44\n",
      "38/38 - 1s - 20ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/44\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/44\n",
      "38/38 - 0s - 13ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/44\n",
      "38/38 - 1s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/44\n",
      "38/38 - 1s - 20ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/44\n",
      "38/38 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/44\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/44\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/44\n",
      "38/38 - 1s - 19ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 30/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 31/44\n",
      "38/38 - 1s - 15ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 32/44\n",
      "38/38 - 1s - 19ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 33/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 34/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 35/44\n",
      "38/38 - 1s - 16ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 36/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 37/44\n",
      "38/38 - 1s - 19ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 38/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 39/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 40/44\n",
      "38/38 - 1s - 14ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 41/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 42/44\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 43/44\n",
      "38/38 - 1s - 17ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 44/44\n",
      "38/38 - 1s - 18ms/step - accuracy: 0.6440 - loss: nan\n",
      "10/10 - 0s - 41ms/step\n",
      "Epoch 1/44\n",
      "Epoch 1/44\n",
      "Epoch 1/44\n",
      "Epoch 1/44\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m7.492    \u001b[39m | \u001b[39m369.9    \u001b[39m | \u001b[39m0.1818   \u001b[39m | \u001b[39m0.05502  \u001b[39m | \u001b[39m44.34    \u001b[39m | \u001b[39m2.05     \u001b[39m | \u001b[39m1.864    \u001b[39m | \u001b[39m1.582    \u001b[39m | \u001b[39m0.6157   \u001b[39m | \u001b[39m22.55    \u001b[39m | \u001b[39m0.2921   \u001b[39m | \u001b[39m2.565    \u001b[39m |\n",
      "Epoch 1/67\n",
      "17/17 - 6s - 349ms/step - accuracy: 0.3788 - loss: 14.5012\n",
      "Epoch 2/67\n",
      "17/17 - 1s - 71ms/step - accuracy: 0.5488 - loss: 6.4763\n",
      "Epoch 3/67\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.5842 - loss: 3.4622\n",
      "Epoch 4/67\n",
      "17/17 - 1s - 47ms/step - accuracy: 0.5853 - loss: 3.2214\n",
      "Epoch 5/67\n",
      "17/17 - 1s - 50ms/step - accuracy: 0.6266 - loss: 2.2342\n",
      "Epoch 6/67\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.6201 - loss: 2.2094\n",
      "Epoch 7/67\n",
      "17/17 - 1s - 61ms/step - accuracy: 0.6196 - loss: 1.9134\n",
      "Epoch 8/67\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.5753 - loss: 3.0101\n",
      "Epoch 9/67\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.5801 - loss: 5.0698\n",
      "Epoch 10/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5649 - loss: 4.1743\n",
      "Epoch 11/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5625 - loss: 4.3483\n",
      "Epoch 12/67\n",
      "17/17 - 1s - 59ms/step - accuracy: 0.5672 - loss: 5.7257\n",
      "Epoch 13/67\n",
      "17/17 - 1s - 46ms/step - accuracy: 0.5815 - loss: 3.2922\n",
      "Epoch 14/67\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6012 - loss: 2.9866\n",
      "Epoch 15/67\n",
      "17/17 - 1s - 51ms/step - accuracy: 0.5591 - loss: 4.9585\n",
      "Epoch 16/67\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.5510 - loss: 6.8555\n",
      "Epoch 17/67\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.5295 - loss: 7.9864\n",
      "Epoch 18/67\n",
      "17/17 - 1s - 59ms/step - accuracy: 0.5357 - loss: 13.5666\n",
      "Epoch 19/67\n",
      "17/17 - 1s - 61ms/step - accuracy: 0.5258 - loss: 11.0739\n",
      "Epoch 20/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5308 - loss: 8.3994\n",
      "Epoch 21/67\n",
      "17/17 - 1s - 42ms/step - accuracy: 0.5403 - loss: 7.7692\n",
      "Epoch 22/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5235 - loss: 10.7717\n",
      "Epoch 23/67\n",
      "17/17 - 1s - 44ms/step - accuracy: 0.5478 - loss: 12.4044\n",
      "Epoch 24/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5388 - loss: 12.1137\n",
      "Epoch 25/67\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.5448 - loss: 10.0798\n",
      "Epoch 26/67\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.5416 - loss: 10.5260\n",
      "Epoch 27/67\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.5475 - loss: 11.4671\n",
      "Epoch 28/67\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.5409 - loss: 11.8617\n",
      "Epoch 29/67\n",
      "17/17 - 1s - 61ms/step - accuracy: 0.5512 - loss: 9.1173\n",
      "Epoch 30/67\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.5547 - loss: 7.8442\n",
      "Epoch 31/67\n",
      "17/17 - 1s - 54ms/step - accuracy: 0.5442 - loss: 8.7099\n",
      "Epoch 32/67\n",
      "17/17 - 1s - 54ms/step - accuracy: 0.5613 - loss: 8.3172\n",
      "Epoch 33/67\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.5456 - loss: 5.4809\n",
      "Epoch 34/67\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.5453 - loss: 7.4135\n",
      "Epoch 35/67\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.5472 - loss: 8.9215\n",
      "Epoch 36/67\n",
      "17/17 - 1s - 60ms/step - accuracy: 0.5224 - loss: 11.8096\n",
      "Epoch 37/67\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.5534 - loss: 8.9838\n",
      "Epoch 38/67\n",
      "17/17 - 1s - 43ms/step - accuracy: 0.5334 - loss: 8.4594\n",
      "Epoch 39/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5506 - loss: 7.2740\n",
      "Epoch 40/67\n",
      "17/17 - 1s - 50ms/step - accuracy: 0.5555 - loss: 5.1902\n",
      "Epoch 41/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5377 - loss: 8.0520\n",
      "Epoch 42/67\n",
      "17/17 - 1s - 51ms/step - accuracy: 0.5458 - loss: 5.7578\n",
      "Epoch 43/67\n",
      "17/17 - 1s - 48ms/step - accuracy: 0.5613 - loss: 4.7776\n",
      "Epoch 44/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5477 - loss: 6.1977\n",
      "Epoch 45/67\n",
      "17/17 - 1s - 54ms/step - accuracy: 0.5559 - loss: 6.7088\n",
      "Epoch 46/67\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.5349 - loss: 7.9919\n",
      "Epoch 47/67\n",
      "17/17 - 1s - 59ms/step - accuracy: 0.5560 - loss: 7.4101\n",
      "Epoch 48/67\n",
      "17/17 - 1s - 55ms/step - accuracy: 0.5457 - loss: 8.6535\n",
      "Epoch 49/67\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.5426 - loss: 9.1292\n",
      "Epoch 50/67\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.5332 - loss: 6.4540\n",
      "Epoch 51/67\n",
      "17/17 - 1s - 62ms/step - accuracy: 0.5408 - loss: 6.5623\n",
      "Epoch 52/67\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.5374 - loss: 7.4346\n",
      "Epoch 53/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5520 - loss: 9.6050\n",
      "Epoch 54/67\n",
      "17/17 - 1s - 53ms/step - accuracy: 0.5446 - loss: 9.6875\n",
      "Epoch 55/67\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.5342 - loss: 7.9552\n",
      "Epoch 56/67\n",
      "17/17 - 1s - 42ms/step - accuracy: 0.5397 - loss: 11.6494\n",
      "Epoch 57/67\n",
      "17/17 - 1s - 58ms/step - accuracy: 0.5412 - loss: 8.9759\n",
      "Epoch 58/67\n",
      "17/17 - 1s - 49ms/step - accuracy: 0.5625 - loss: 7.4765\n",
      "Epoch 59/67\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.5431 - loss: 6.7980\n",
      "Epoch 60/67\n",
      "17/17 - 1s - 56ms/step - accuracy: 0.5377 - loss: 5.1430\n",
      "Epoch 61/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5541 - loss: 5.1872\n",
      "Epoch 62/67\n",
      "17/17 - 1s - 62ms/step - accuracy: 0.5506 - loss: 5.5006\n",
      "Epoch 63/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5566 - loss: 5.5360\n",
      "Epoch 64/67\n",
      "17/17 - 1s - 57ms/step - accuracy: 0.5553 - loss: 5.3081\n",
      "Epoch 65/67\n",
      "17/17 - 1s - 52ms/step - accuracy: 0.5557 - loss: 4.4608\n",
      "Epoch 66/67\n",
      "17/17 - 1s - 86ms/step - accuracy: 0.5425 - loss: 7.3934\n",
      "Epoch 67/67\n",
      "17/17 - 1s - 59ms/step - accuracy: 0.5666 - loss: 8.3538\n",
      "5/5 - 0s - 90ms/step\n",
      "Epoch 1/67\n",
      "Epoch 1/67\n",
      "Epoch 1/67\n",
      "Epoch 1/67\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.105    \u001b[39m | \u001b[39m828.1    \u001b[39m | \u001b[39m0.1997   \u001b[39m | \u001b[39m0.1543   \u001b[39m | \u001b[39m67.39    \u001b[39m | \u001b[39m1.093    \u001b[39m | \u001b[39m2.215    \u001b[39m | \u001b[39m1.341    \u001b[39m | \u001b[39m0.0744   \u001b[39m | \u001b[39m95.4     \u001b[39m | \u001b[39m0.9656   \u001b[39m | \u001b[39m5.659    \u001b[39m |\n",
      "Epoch 1/30\n",
      "50/50 - 4s - 71ms/step - accuracy: 0.4525 - loss: 9.6910\n",
      "Epoch 2/30\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.5109 - loss: 6.1015\n",
      "Epoch 3/30\n",
      "50/50 - 3s - 54ms/step - accuracy: 0.5198 - loss: 4.2291\n",
      "Epoch 4/30\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.5456 - loss: 2.3634\n",
      "Epoch 5/30\n",
      "50/50 - 2s - 31ms/step - accuracy: 0.5878 - loss: 1.4345\n",
      "Epoch 6/30\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.5906 - loss: 1.2650\n",
      "Epoch 7/30\n",
      "50/50 - 1s - 27ms/step - accuracy: 0.6173 - loss: 1.0783\n",
      "Epoch 8/30\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.6446 - loss: 1.0201\n",
      "Epoch 9/30\n",
      "50/50 - 1s - 27ms/step - accuracy: 0.6658 - loss: 0.9831\n",
      "Epoch 10/30\n",
      "50/50 - 1s - 27ms/step - accuracy: 0.6965 - loss: 0.8950\n",
      "Epoch 11/30\n",
      "50/50 - 3s - 56ms/step - accuracy: 0.6964 - loss: 0.8906\n",
      "Epoch 12/30\n",
      "50/50 - 2s - 31ms/step - accuracy: 0.7054 - loss: 0.8654\n",
      "Epoch 13/30\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.7172 - loss: 0.8261\n",
      "Epoch 14/30\n",
      "50/50 - 1s - 30ms/step - accuracy: 0.7281 - loss: 0.8048\n",
      "Epoch 15/30\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.7230 - loss: 0.8001\n",
      "Epoch 16/30\n",
      "50/50 - 3s - 55ms/step - accuracy: 0.7261 - loss: 0.7926\n",
      "Epoch 17/30\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.7312 - loss: 0.7684\n",
      "Epoch 18/30\n",
      "50/50 - 3s - 51ms/step - accuracy: 0.7308 - loss: 0.7687\n",
      "Epoch 19/30\n",
      "50/50 - 3s - 52ms/step - accuracy: 0.7427 - loss: 0.7463\n",
      "Epoch 20/30\n",
      "50/50 - 1s - 27ms/step - accuracy: 0.7387 - loss: 0.7490\n",
      "Epoch 21/30\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.7438 - loss: 0.7407\n",
      "Epoch 22/30\n",
      "50/50 - 2s - 49ms/step - accuracy: 0.7430 - loss: 0.7309\n",
      "Epoch 23/30\n",
      "50/50 - 1s - 28ms/step - accuracy: 0.7469 - loss: 0.7175\n",
      "Epoch 24/30\n",
      "50/50 - 2s - 30ms/step - accuracy: 0.7510 - loss: 0.7129\n",
      "Epoch 25/30\n",
      "50/50 - 1s - 29ms/step - accuracy: 0.7526 - loss: 0.7037\n",
      "Epoch 26/30\n",
      "50/50 - 1s - 26ms/step - accuracy: 0.7531 - loss: 0.7066\n",
      "Epoch 27/30\n",
      "50/50 - 3s - 57ms/step - accuracy: 0.7566 - loss: 0.6926\n",
      "Epoch 28/30\n",
      "50/50 - 2s - 50ms/step - accuracy: 0.7516 - loss: 0.6987\n",
      "Epoch 29/30\n",
      "50/50 - 2s - 32ms/step - accuracy: 0.7575 - loss: 0.6873\n",
      "Epoch 30/30\n",
      "50/50 - 1s - 28ms/step - accuracy: 0.7592 - loss: 0.6811\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CAA7E8CB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "13/13 - 0s - 36ms/step\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.742    \u001b[39m | \u001b[39m278.1    \u001b[39m | \u001b[39m0.6842   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m29.76    \u001b[39m | \u001b[39m1.99     \u001b[39m | \u001b[39m1.069    \u001b[39m | \u001b[39m2.819    \u001b[39m | \u001b[39m0.2662   \u001b[39m | \u001b[39m69.63    \u001b[39m | \u001b[39m0.3117   \u001b[39m | \u001b[39m3.64     \u001b[39m |\n",
      "Epoch 1/95\n",
      "40/40 - 4s - 99ms/step - accuracy: 0.4343 - loss: 2553.3748\n",
      "Epoch 2/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4814 - loss: 24.9932\n",
      "Epoch 3/95\n",
      "40/40 - 2s - 39ms/step - accuracy: 0.4204 - loss: 20.0156\n",
      "Epoch 4/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4179 - loss: 19.8581\n",
      "Epoch 5/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4365 - loss: 22.2539\n",
      "Epoch 6/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4122 - loss: 24.4821\n",
      "Epoch 7/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4237 - loss: 24.8767\n",
      "Epoch 8/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4051 - loss: 307.9977\n",
      "Epoch 9/95\n",
      "40/40 - 1s - 25ms/step - accuracy: 0.4060 - loss: 22.9104\n",
      "Epoch 10/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4256 - loss: 183.6364\n",
      "Epoch 11/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4038 - loss: 21.6424\n",
      "Epoch 12/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4142 - loss: 166.4482\n",
      "Epoch 13/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4260 - loss: 22.1046\n",
      "Epoch 14/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4171 - loss: 22.4859\n",
      "Epoch 15/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4122 - loss: 55.7357\n",
      "Epoch 16/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4143 - loss: 22.3671\n",
      "Epoch 17/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4082 - loss: 24.4876\n",
      "Epoch 18/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4248 - loss: 24.2009\n",
      "Epoch 19/95\n",
      "40/40 - 1s - 17ms/step - accuracy: 0.4268 - loss: 22.7361\n",
      "Epoch 20/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4167 - loss: 24.7554\n",
      "Epoch 21/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4252 - loss: 22.5678\n",
      "Epoch 22/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4469 - loss: 21.3867\n",
      "Epoch 23/95\n",
      "40/40 - 1s - 17ms/step - accuracy: 0.4138 - loss: 23.5217\n",
      "Epoch 24/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4469 - loss: 21.7016\n",
      "Epoch 25/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4045 - loss: 25.0302\n",
      "Epoch 26/95\n",
      "40/40 - 1s - 36ms/step - accuracy: 0.4214 - loss: 23.3683\n",
      "Epoch 27/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4231 - loss: 23.1992\n",
      "Epoch 28/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4389 - loss: 22.2187\n",
      "Epoch 29/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4180 - loss: 22.4111\n",
      "Epoch 30/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4221 - loss: 21.7729\n",
      "Epoch 31/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4480 - loss: 22.7517\n",
      "Epoch 32/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4143 - loss: 11826.4355\n",
      "Epoch 33/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4197 - loss: 711.9238\n",
      "Epoch 34/95\n",
      "40/40 - 1s - 36ms/step - accuracy: 0.4235 - loss: 22.6702\n",
      "Epoch 35/95\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.4066 - loss: 23.7091\n",
      "Epoch 36/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4215 - loss: 20.6649\n",
      "Epoch 37/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4246 - loss: 22.6758\n",
      "Epoch 38/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4255 - loss: 23.7938\n",
      "Epoch 39/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4297 - loss: 22.8553\n",
      "Epoch 40/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4165 - loss: 22.8910\n",
      "Epoch 41/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4017 - loss: 25.1865\n",
      "Epoch 42/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4186 - loss: 21.7336\n",
      "Epoch 43/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4431 - loss: 24.6165\n",
      "Epoch 44/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4196 - loss: 22.7908\n",
      "Epoch 45/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4124 - loss: 23.8443\n",
      "Epoch 46/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4197 - loss: 22.2955\n",
      "Epoch 47/95\n",
      "40/40 - 1s - 35ms/step - accuracy: 0.4180 - loss: 24.8282\n",
      "Epoch 48/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4318 - loss: 21.8121\n",
      "Epoch 49/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4097 - loss: 23.1752\n",
      "Epoch 50/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4297 - loss: 23.9118\n",
      "Epoch 51/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4111 - loss: 23.6839\n",
      "Epoch 52/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4087 - loss: 23.2135\n",
      "Epoch 53/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4142 - loss: 23.5693\n",
      "Epoch 54/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4296 - loss: 22.4043\n",
      "Epoch 55/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4361 - loss: 21.5299\n",
      "Epoch 56/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4178 - loss: 27.0540\n",
      "Epoch 57/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4071 - loss: 26.3391\n",
      "Epoch 58/95\n",
      "40/40 - 1s - 17ms/step - accuracy: 0.4175 - loss: 22.4084\n",
      "Epoch 59/95\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.4162 - loss: 44.7101\n",
      "Epoch 60/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4227 - loss: 24.8787\n",
      "Epoch 61/95\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.4148 - loss: 24.4020\n",
      "Epoch 62/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4258 - loss: 23.8281\n",
      "Epoch 63/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4262 - loss: 22.8904\n",
      "Epoch 64/95\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.4304 - loss: 23.8270\n",
      "Epoch 65/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4063 - loss: 22.6458\n",
      "Epoch 66/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4305 - loss: 22.6668\n",
      "Epoch 67/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4196 - loss: 23.0148\n",
      "Epoch 68/95\n",
      "40/40 - 1s - 24ms/step - accuracy: 0.4037 - loss: 23.4322\n",
      "Epoch 69/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4183 - loss: 23.9741\n",
      "Epoch 70/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4153 - loss: 30.1236\n",
      "Epoch 71/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4406 - loss: 22.2529\n",
      "Epoch 72/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4067 - loss: 29.3182\n",
      "Epoch 73/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4207 - loss: 21.9783\n",
      "Epoch 74/95\n",
      "40/40 - 1s - 36ms/step - accuracy: 0.4304 - loss: 21.8775\n",
      "Epoch 75/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4300 - loss: 23.6595\n",
      "Epoch 76/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4164 - loss: 24.7828\n",
      "Epoch 77/95\n",
      "40/40 - 1s - 21ms/step - accuracy: 0.4153 - loss: 23.2750\n",
      "Epoch 78/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4126 - loss: 23.0374\n",
      "Epoch 79/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4359 - loss: 21.4237\n",
      "Epoch 80/95\n",
      "40/40 - 1s - 36ms/step - accuracy: 0.3905 - loss: 25.6199\n",
      "Epoch 81/95\n",
      "40/40 - 1s - 16ms/step - accuracy: 0.4272 - loss: 23.4117\n",
      "Epoch 82/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4270 - loss: 22.0158\n",
      "Epoch 83/95\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.4280 - loss: 23.2207\n",
      "Epoch 84/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4023 - loss: 22.0718\n",
      "Epoch 85/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4337 - loss: 20.9253\n",
      "Epoch 86/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4082 - loss: 24.0685\n",
      "Epoch 87/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4074 - loss: 23.8267\n",
      "Epoch 88/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4392 - loss: 22.0185\n",
      "Epoch 89/95\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.3870 - loss: 24.1809\n",
      "Epoch 90/95\n",
      "40/40 - 1s - 37ms/step - accuracy: 0.4219 - loss: 23.5316\n",
      "Epoch 91/95\n",
      "40/40 - 1s - 22ms/step - accuracy: 0.4215 - loss: 23.4091\n",
      "Epoch 92/95\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.4215 - loss: 24.7513\n",
      "Epoch 93/95\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4244 - loss: 23.2340\n",
      "Epoch 94/95\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4053 - loss: 24.5720\n",
      "Epoch 95/95\n",
      "40/40 - 1s - 23ms/step - accuracy: 0.4114 - loss: 24.0068\n",
      "10/10 - 0s - 43ms/step\n",
      "Epoch 1/95\n",
      "Epoch 1/95\n",
      "Epoch 1/95\n",
      "Epoch 1/95\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.92     \u001b[39m | \u001b[39m347.9    \u001b[39m | \u001b[39m0.9696   \u001b[39m | \u001b[39m0.2325   \u001b[39m | \u001b[39m95.16    \u001b[39m | \u001b[39m2.79     \u001b[39m | \u001b[39m2.196    \u001b[39m | \u001b[39m2.844    \u001b[39m | \u001b[39m0.09761  \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.04523  \u001b[39m | \u001b[39m2.277    \u001b[39m |\n",
      "Epoch 1/42\n",
      "34/34 - 6s - 166ms/step - accuracy: 0.4820 - loss: 8.0378\n",
      "Epoch 2/42\n",
      "34/34 - 1s - 43ms/step - accuracy: 0.5887 - loss: 4.5489\n",
      "Epoch 3/42\n",
      "34/34 - 2s - 46ms/step - accuracy: 0.5292 - loss: 5.0326\n",
      "Epoch 4/42\n",
      "34/34 - 2s - 51ms/step - accuracy: 0.5582 - loss: 5.1925\n",
      "Epoch 5/42\n",
      "34/34 - 2s - 51ms/step - accuracy: 0.5475 - loss: 4.4691\n",
      "Epoch 6/42\n",
      "34/34 - 2s - 51ms/step - accuracy: 0.5549 - loss: 5.6304\n",
      "Epoch 7/42\n",
      "34/34 - 2s - 53ms/step - accuracy: 0.5096 - loss: 13.0926\n",
      "Epoch 8/42\n",
      "34/34 - 2s - 51ms/step - accuracy: 0.5108 - loss: 14.0017\n",
      "Epoch 9/42\n",
      "34/34 - 2s - 49ms/step - accuracy: 0.5075 - loss: 13.4432\n",
      "Epoch 10/42\n",
      "34/34 - 2s - 50ms/step - accuracy: 0.5248 - loss: 15.4120\n",
      "Epoch 11/42\n",
      "34/34 - 1s - 40ms/step - accuracy: 0.5233 - loss: 12.2595\n",
      "Epoch 12/42\n",
      "34/34 - 3s - 86ms/step - accuracy: 0.5064 - loss: 14.0171\n",
      "Epoch 13/42\n",
      "34/34 - 2s - 50ms/step - accuracy: 0.5242 - loss: 15.8198\n",
      "Epoch 14/42\n",
      "34/34 - 2s - 48ms/step - accuracy: 0.5064 - loss: 16.2407\n",
      "Epoch 15/42\n",
      "34/34 - 2s - 47ms/step - accuracy: 0.5248 - loss: 16.8027\n",
      "Epoch 16/42\n",
      "34/34 - 1s - 34ms/step - accuracy: 0.5166 - loss: 13.1115\n",
      "Epoch 17/42\n",
      "34/34 - 1s - 28ms/step - accuracy: 0.5223 - loss: 12.7728\n",
      "Epoch 18/42\n",
      "34/34 - 1s - 38ms/step - accuracy: 0.5195 - loss: 14.2033\n",
      "Epoch 19/42\n",
      "34/34 - 2s - 45ms/step - accuracy: 0.5297 - loss: 13.5141\n",
      "Epoch 20/42\n",
      "34/34 - 1s - 40ms/step - accuracy: 0.5117 - loss: 13.3804\n",
      "Epoch 21/42\n",
      "34/34 - 1s - 38ms/step - accuracy: 0.5229 - loss: 15.6151\n",
      "Epoch 22/42\n",
      "34/34 - 1s - 37ms/step - accuracy: 0.5004 - loss: 18.6802\n",
      "Epoch 23/42\n",
      "34/34 - 1s - 41ms/step - accuracy: 0.5201 - loss: 11.4064\n",
      "Epoch 24/42\n",
      "34/34 - 1s - 37ms/step - accuracy: 0.5427 - loss: 6.3739\n",
      "Epoch 25/42\n",
      "34/34 - 1s - 38ms/step - accuracy: 0.5471 - loss: 8.8100\n",
      "Epoch 26/42\n",
      "34/34 - 1s - 40ms/step - accuracy: 0.5334 - loss: 8.9970\n",
      "Epoch 27/42\n",
      "34/34 - 1s - 42ms/step - accuracy: 0.5403 - loss: 8.8470\n",
      "Epoch 28/42\n",
      "34/34 - 1s - 35ms/step - accuracy: 0.5345 - loss: 14.0725\n",
      "Epoch 29/42\n",
      "34/34 - 1s - 30ms/step - accuracy: 0.5354 - loss: 9.7812\n",
      "Epoch 30/42\n",
      "34/34 - 1s - 37ms/step - accuracy: 0.5438 - loss: 12.0265\n",
      "Epoch 31/42\n",
      "34/34 - 1s - 44ms/step - accuracy: 0.5435 - loss: 8.7003\n",
      "Epoch 32/42\n",
      "34/34 - 1s - 42ms/step - accuracy: 0.5558 - loss: 6.8011\n",
      "Epoch 33/42\n",
      "34/34 - 1s - 41ms/step - accuracy: 0.5239 - loss: 8.8464\n",
      "Epoch 34/42\n",
      "34/34 - 1s - 39ms/step - accuracy: 0.5261 - loss: 12.5402\n",
      "Epoch 35/42\n",
      "34/34 - 2s - 52ms/step - accuracy: 0.5576 - loss: 10.6138\n",
      "Epoch 36/42\n",
      "34/34 - 2s - 49ms/step - accuracy: 0.5402 - loss: 6.4375\n",
      "Epoch 37/42\n",
      "34/34 - 2s - 71ms/step - accuracy: 0.5572 - loss: 6.4262\n",
      "Epoch 38/42\n",
      "34/34 - 1s - 39ms/step - accuracy: 0.5441 - loss: 6.9057\n",
      "Epoch 39/42\n",
      "34/34 - 2s - 47ms/step - accuracy: 0.5353 - loss: 12.3263\n",
      "Epoch 40/42\n",
      "34/34 - 1s - 42ms/step - accuracy: 0.5444 - loss: 7.7327\n",
      "Epoch 41/42\n",
      "34/34 - 2s - 47ms/step - accuracy: 0.5330 - loss: 7.3085\n",
      "Epoch 42/42\n",
      "34/34 - 1s - 34ms/step - accuracy: 0.5376 - loss: 6.8343\n",
      "9/9 - 1s - 62ms/step\n",
      "Epoch 1/42\n",
      "Epoch 1/42\n",
      "Epoch 1/42\n",
      "Epoch 1/42\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m3.498    \u001b[39m | \u001b[39m417.1    \u001b[39m | \u001b[39m0.8287   \u001b[39m | \u001b[39m0.107    \u001b[39m | \u001b[39m42.47    \u001b[39m | \u001b[39m2.085    \u001b[39m | \u001b[39m1.282    \u001b[39m | \u001b[39m2.604    \u001b[39m | \u001b[39m0.08381  \u001b[39m | \u001b[39m98.82    \u001b[39m | \u001b[39m0.7722   \u001b[39m | \u001b[39m1.391    \u001b[39m |\n",
      "Epoch 1/82\n",
      "17/17 - 2s - 118ms/step - accuracy: 0.5585 - loss: nan\n",
      "Epoch 2/82\n",
      "17/17 - 1s - 35ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/82\n",
      "17/17 - 1s - 33ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/82\n",
      "17/17 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/82\n",
      "17/17 - 1s - 31ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/82\n",
      "17/17 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/82\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/82\n",
      "17/17 - 1s - 33ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/82\n",
      "17/17 - 0s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/82\n",
      "17/17 - 1s - 32ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/82\n",
      "17/17 - 0s - 25ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/82\n",
      "17/17 - 0s - 24ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/82\n",
      "17/17 - 0s - 25ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/82\n",
      "17/17 - 1s - 30ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/82\n",
      "17/17 - 0s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/82\n",
      "17/17 - 0s - 21ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/82\n",
      "17/17 - 0s - 23ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/82\n",
      "17/17 - 0s - 26ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/82\n",
      "17/17 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/82\n",
      "17/17 - 1s - 35ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/82\n",
      "17/17 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 30/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 31/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 32/82\n",
      "17/17 - 1s - 33ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 33/82\n",
      "17/17 - 1s - 30ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 34/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 35/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 36/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 37/82\n",
      "17/17 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 38/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 39/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 40/82\n",
      "17/17 - 1s - 75ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 41/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 42/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 43/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 44/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 45/82\n",
      "17/17 - 0s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 46/82\n",
      "17/17 - 0s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 47/82\n",
      "17/17 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 48/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 49/82\n",
      "17/17 - 1s - 31ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 50/82\n",
      "17/17 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 51/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 52/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 53/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 54/82\n",
      "17/17 - 1s - 78ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 55/82\n",
      "17/17 - 1s - 82ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 56/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 57/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 58/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 59/82\n",
      "17/17 - 1s - 43ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 60/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 61/82\n",
      "17/17 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 62/82\n",
      "17/17 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 63/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 64/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 65/82\n",
      "17/17 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 66/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 67/82\n",
      "17/17 - 1s - 37ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 68/82\n",
      "17/17 - 0s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 69/82\n",
      "17/17 - 0s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 70/82\n",
      "17/17 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 71/82\n",
      "17/17 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 72/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 73/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 74/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 75/82\n",
      "17/17 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 76/82\n",
      "17/17 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 77/82\n",
      "17/17 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 78/82\n",
      "17/17 - 1s - 35ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 79/82\n",
      "17/17 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 80/82\n",
      "17/17 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 81/82\n",
      "17/17 - 1s - 43ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 82/82\n",
      "17/17 - 1s - 32ms/step - accuracy: 0.6440 - loss: nan\n",
      "5/5 - 0s - 69ms/step\n",
      "Epoch 1/82\n",
      "Epoch 1/82\n",
      "Epoch 1/82\n",
      "Epoch 1/82\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.0497   \u001b[39m | \u001b[39m852.4    \u001b[39m | \u001b[39m0.7069   \u001b[39m | \u001b[39m0.2187   \u001b[39m | \u001b[39m81.7     \u001b[39m | \u001b[39m1.148    \u001b[39m | \u001b[39m1.717    \u001b[39m | \u001b[39m1.232    \u001b[39m | \u001b[39m0.8645   \u001b[39m | \u001b[39m66.1     \u001b[39m | \u001b[39m0.3309   \u001b[39m | \u001b[39m0.4449   \u001b[39m |\n",
      "Epoch 1/91\n",
      "30/30 - 4s - 140ms/step - accuracy: 0.5522 - loss: 1.5470\n",
      "Epoch 2/91\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.6942 - loss: 0.9550\n",
      "Epoch 3/91\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.7130 - loss: 0.8626\n",
      "Epoch 4/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.7267 - loss: 0.8065\n",
      "Epoch 5/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.7405 - loss: 0.7670\n",
      "Epoch 6/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.7465 - loss: 0.7381\n",
      "Epoch 7/91\n",
      "30/30 - 1s - 41ms/step - accuracy: 0.7543 - loss: 0.7100\n",
      "Epoch 8/91\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.7642 - loss: 0.6896\n",
      "Epoch 9/91\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.7669 - loss: 0.6720\n",
      "Epoch 10/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.7778 - loss: 0.6486\n",
      "Epoch 11/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.7774 - loss: 0.6481\n",
      "Epoch 12/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.7841 - loss: 0.6238\n",
      "Epoch 13/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.7826 - loss: 0.6258\n",
      "Epoch 14/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.7893 - loss: 0.6043\n",
      "Epoch 15/91\n",
      "30/30 - 1s - 45ms/step - accuracy: 0.7930 - loss: 0.5991\n",
      "Epoch 16/91\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.7950 - loss: 0.5854\n",
      "Epoch 17/91\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.7947 - loss: 0.5854\n",
      "Epoch 18/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.8011 - loss: 0.5701\n",
      "Epoch 19/91\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.8028 - loss: 0.5567\n",
      "Epoch 20/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.8043 - loss: 0.5553\n",
      "Epoch 21/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8076 - loss: 0.5455\n",
      "Epoch 22/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8139 - loss: 0.5265\n",
      "Epoch 23/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8165 - loss: 0.5217\n",
      "Epoch 24/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8173 - loss: 0.5163\n",
      "Epoch 25/91\n",
      "30/30 - 1s - 38ms/step - accuracy: 0.8190 - loss: 0.5141\n",
      "Epoch 26/91\n",
      "30/30 - 1s - 42ms/step - accuracy: 0.8224 - loss: 0.5062\n",
      "Epoch 27/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.8296 - loss: 0.4860\n",
      "Epoch 28/91\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.8287 - loss: 0.4873\n",
      "Epoch 29/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.8242 - loss: 0.4860\n",
      "Epoch 30/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8348 - loss: 0.4639\n",
      "Epoch 31/91\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.8342 - loss: 0.4654\n",
      "Epoch 32/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.8327 - loss: 0.4676\n",
      "Epoch 33/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.8397 - loss: 0.4509\n",
      "Epoch 34/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8465 - loss: 0.4343\n",
      "Epoch 35/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8483 - loss: 0.4286\n",
      "Epoch 36/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8486 - loss: 0.4295\n",
      "Epoch 37/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8523 - loss: 0.4128\n",
      "Epoch 38/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.8595 - loss: 0.4028\n",
      "Epoch 39/91\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.8541 - loss: 0.4004\n",
      "Epoch 40/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8584 - loss: 0.3955\n",
      "Epoch 41/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.8614 - loss: 0.3899\n",
      "Epoch 42/91\n",
      "30/30 - 1s - 49ms/step - accuracy: 0.8621 - loss: 0.3849\n",
      "Epoch 43/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8635 - loss: 0.3851\n",
      "Epoch 44/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8699 - loss: 0.3658\n",
      "Epoch 45/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.8696 - loss: 0.3678\n",
      "Epoch 46/91\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.8758 - loss: 0.3541\n",
      "Epoch 47/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.8779 - loss: 0.3471\n",
      "Epoch 48/91\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.8791 - loss: 0.3443\n",
      "Epoch 49/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8785 - loss: 0.3436\n",
      "Epoch 50/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.8820 - loss: 0.3295\n",
      "Epoch 51/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.8818 - loss: 0.3288\n",
      "Epoch 52/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8849 - loss: 0.3269\n",
      "Epoch 53/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8849 - loss: 0.3314\n",
      "Epoch 54/91\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.8860 - loss: 0.3149\n",
      "Epoch 55/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.8870 - loss: 0.3199\n",
      "Epoch 56/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.8927 - loss: 0.3067\n",
      "Epoch 57/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.8909 - loss: 0.3044\n",
      "Epoch 58/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.8910 - loss: 0.3140\n",
      "Epoch 59/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.8958 - loss: 0.2950\n",
      "Epoch 60/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.8961 - loss: 0.2974\n",
      "Epoch 61/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.8960 - loss: 0.2892\n",
      "Epoch 62/91\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.9007 - loss: 0.2816\n",
      "Epoch 63/91\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.9041 - loss: 0.2752\n",
      "Epoch 64/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.9017 - loss: 0.2775\n",
      "Epoch 65/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.9051 - loss: 0.2721\n",
      "Epoch 66/91\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.9044 - loss: 0.2720\n",
      "Epoch 67/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.9094 - loss: 0.2573\n",
      "Epoch 68/91\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.9094 - loss: 0.2577\n",
      "Epoch 69/91\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.9123 - loss: 0.2456\n",
      "Epoch 70/91\n",
      "30/30 - 1s - 33ms/step - accuracy: 0.9129 - loss: 0.2497\n",
      "Epoch 71/91\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.9099 - loss: 0.2583\n",
      "Epoch 72/91\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.9120 - loss: 0.2540\n",
      "Epoch 73/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.9155 - loss: 0.2370\n",
      "Epoch 74/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.9162 - loss: 0.2418\n",
      "Epoch 75/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.9168 - loss: 0.2376\n",
      "Epoch 76/91\n",
      "30/30 - 1s - 36ms/step - accuracy: 0.9174 - loss: 0.2386\n",
      "Epoch 77/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.9202 - loss: 0.2267\n",
      "Epoch 78/91\n",
      "30/30 - 1s - 31ms/step - accuracy: 0.9202 - loss: 0.2305\n",
      "Epoch 79/91\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.9170 - loss: 0.2371\n",
      "Epoch 80/91\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.9209 - loss: 0.2293\n",
      "Epoch 81/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.9273 - loss: 0.2116\n",
      "Epoch 82/91\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.9234 - loss: 0.2257\n",
      "Epoch 83/91\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.9246 - loss: 0.2215\n",
      "Epoch 84/91\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.9248 - loss: 0.2183\n",
      "Epoch 85/91\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.9266 - loss: 0.2088\n",
      "Epoch 86/91\n",
      "30/30 - 1s - 44ms/step - accuracy: 0.9255 - loss: 0.2155\n",
      "Epoch 87/91\n",
      "30/30 - 1s - 34ms/step - accuracy: 0.9266 - loss: 0.2133\n",
      "Epoch 88/91\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.9296 - loss: 0.2074\n",
      "Epoch 89/91\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.9265 - loss: 0.2113\n",
      "Epoch 90/91\n",
      "30/30 - 1s - 35ms/step - accuracy: 0.9288 - loss: 0.2077\n",
      "Epoch 91/91\n",
      "30/30 - 1s - 47ms/step - accuracy: 0.9350 - loss: 0.1903\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CAAEB02200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8/8 - 0s - 59ms/step\n",
      "Epoch 1/91\n",
      "Epoch 1/91\n",
      "Epoch 1/91\n",
      "Epoch 1/91\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.799    \u001b[39m | \u001b[39m460.1    \u001b[39m | \u001b[39m0.7296   \u001b[39m | \u001b[39m0.1913   \u001b[39m | \u001b[39m90.98    \u001b[39m | \u001b[39m1.944    \u001b[39m | \u001b[39m1.239    \u001b[39m | \u001b[39m2.426    \u001b[39m | \u001b[39m0.7632   \u001b[39m | \u001b[39m60.51    \u001b[39m | \u001b[39m0.771    \u001b[39m | \u001b[39m3.457    \u001b[39m |\n",
      "Epoch 1/23\n",
      "26/26 - 4s - 145ms/step - accuracy: 0.3477 - loss: 1914216.5000\n",
      "Epoch 2/23\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.4116 - loss: 6289.1504\n",
      "Epoch 3/23\n",
      "26/26 - 1s - 26ms/step - accuracy: 0.4721 - loss: 1110.3193\n",
      "Epoch 4/23\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.5020 - loss: 376.1506\n",
      "Epoch 5/23\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.5403 - loss: 255.5661\n",
      "Epoch 6/23\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.5212 - loss: 181.9994\n",
      "Epoch 7/23\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.5139 - loss: 147.2508\n",
      "Epoch 8/23\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.5225 - loss: 132.8835\n",
      "Epoch 9/23\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.5150 - loss: 112.1115\n",
      "Epoch 10/23\n",
      "26/26 - 0s - 16ms/step - accuracy: 0.4928 - loss: 101.8946\n",
      "Epoch 11/23\n",
      "26/26 - 1s - 32ms/step - accuracy: 0.5329 - loss: 95.5073\n",
      "Epoch 12/23\n",
      "26/26 - 1s - 23ms/step - accuracy: 0.4951 - loss: 91.9668\n",
      "Epoch 13/23\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.5155 - loss: 87.1150\n",
      "Epoch 14/23\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.4770 - loss: 77.6107\n",
      "Epoch 15/23\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.5143 - loss: 60.3456\n",
      "Epoch 16/23\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.5074 - loss: 52.5432\n",
      "Epoch 17/23\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.5116 - loss: 49.2953\n",
      "Epoch 18/23\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.5110 - loss: 44.6777\n",
      "Epoch 19/23\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.4951 - loss: 41.3736\n",
      "Epoch 20/23\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.4992 - loss: 41.5025\n",
      "Epoch 21/23\n",
      "26/26 - 0s - 14ms/step - accuracy: 0.4359 - loss: 63.9864\n",
      "Epoch 22/23\n",
      "26/26 - 1s - 33ms/step - accuracy: 0.4663 - loss: 50.1193\n",
      "Epoch 23/23\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.4842 - loss: 48.6053\n",
      "7/7 - 0s - 54ms/step\n",
      "Epoch 1/23\n",
      "Epoch 1/23\n",
      "Epoch 1/23\n",
      "Epoch 1/23\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.705    \u001b[39m | \u001b[39m542.0    \u001b[39m | \u001b[39m0.02542  \u001b[39m | \u001b[39m0.03237  \u001b[39m | \u001b[39m22.51    \u001b[39m | \u001b[39m2.273    \u001b[39m | \u001b[39m1.629    \u001b[39m | \u001b[39m2.017    \u001b[39m | \u001b[39m0.9085   \u001b[39m | \u001b[39m32.44    \u001b[39m | \u001b[39m0.4104   \u001b[39m | \u001b[39m5.289    \u001b[39m |\n",
      "Epoch 1/94\n",
      "53/53 - 4s - 84ms/step - accuracy: 0.5967 - loss: 3.2811\n",
      "Epoch 2/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.0876\n",
      "Epoch 3/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0595\n",
      "Epoch 4/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0600\n",
      "Epoch 5/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6440 - loss: 1.0533\n",
      "Epoch 6/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6440 - loss: 1.0487\n",
      "Epoch 7/94\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.6425 - loss: 1.0320\n",
      "Epoch 8/94\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.6412 - loss: 1.0132\n",
      "Epoch 9/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.6403 - loss: 0.9944\n",
      "Epoch 10/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6483 - loss: 0.9654\n",
      "Epoch 11/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6499 - loss: 0.9482\n",
      "Epoch 12/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6664 - loss: 0.9145\n",
      "Epoch 13/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.6796 - loss: 0.8697\n",
      "Epoch 14/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6725 - loss: 0.8952\n",
      "Epoch 15/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.6963 - loss: 0.8237\n",
      "Epoch 16/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7083 - loss: 0.7944\n",
      "Epoch 17/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7253 - loss: 0.7627\n",
      "Epoch 18/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7237 - loss: 0.7716\n",
      "Epoch 19/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7318 - loss: 0.7446\n",
      "Epoch 20/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7404 - loss: 0.7273\n",
      "Epoch 21/94\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.7399 - loss: 0.7157\n",
      "Epoch 22/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7486 - loss: 0.7008\n",
      "Epoch 23/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7460 - loss: 0.6961\n",
      "Epoch 24/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7507 - loss: 0.6900\n",
      "Epoch 25/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7535 - loss: 0.6720\n",
      "Epoch 26/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7555 - loss: 0.6676\n",
      "Epoch 27/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7574 - loss: 0.6719\n",
      "Epoch 28/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7540 - loss: 0.6677\n",
      "Epoch 29/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7631 - loss: 0.6529\n",
      "Epoch 30/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7623 - loss: 0.6499\n",
      "Epoch 31/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7587 - loss: 0.6613\n",
      "Epoch 32/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7609 - loss: 0.6528\n",
      "Epoch 33/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7604 - loss: 0.6469\n",
      "Epoch 34/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7661 - loss: 0.6425\n",
      "Epoch 35/94\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.7684 - loss: 0.6315\n",
      "Epoch 36/94\n",
      "53/53 - 1s - 28ms/step - accuracy: 0.7653 - loss: 0.6402\n",
      "Epoch 37/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7624 - loss: 0.6428\n",
      "Epoch 38/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7643 - loss: 0.6382\n",
      "Epoch 39/94\n",
      "53/53 - 1s - 26ms/step - accuracy: 0.7697 - loss: 0.6204\n",
      "Epoch 40/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7680 - loss: 0.6292\n",
      "Epoch 41/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7714 - loss: 0.6150\n",
      "Epoch 42/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7662 - loss: 0.6245\n",
      "Epoch 43/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7705 - loss: 0.6261\n",
      "Epoch 44/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7700 - loss: 0.6246\n",
      "Epoch 45/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7698 - loss: 0.6184\n",
      "Epoch 46/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7757 - loss: 0.6100\n",
      "Epoch 47/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7725 - loss: 0.6130\n",
      "Epoch 48/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7713 - loss: 0.6137\n",
      "Epoch 49/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7738 - loss: 0.6104\n",
      "Epoch 50/94\n",
      "53/53 - 1s - 27ms/step - accuracy: 0.7743 - loss: 0.5995\n",
      "Epoch 51/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7742 - loss: 0.6049\n",
      "Epoch 52/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7741 - loss: 0.6096\n",
      "Epoch 53/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7746 - loss: 0.6023\n",
      "Epoch 54/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7788 - loss: 0.5973\n",
      "Epoch 55/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7751 - loss: 0.5981\n",
      "Epoch 56/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7757 - loss: 0.5965\n",
      "Epoch 57/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7780 - loss: 0.5951\n",
      "Epoch 58/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7754 - loss: 0.6057\n",
      "Epoch 59/94\n",
      "53/53 - 1s - 27ms/step - accuracy: 0.7858 - loss: 0.5815\n",
      "Epoch 60/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7778 - loss: 0.5993\n",
      "Epoch 61/94\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.7802 - loss: 0.5875\n",
      "Epoch 62/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7800 - loss: 0.5909\n",
      "Epoch 63/94\n",
      "53/53 - 1s - 16ms/step - accuracy: 0.7820 - loss: 0.5806\n",
      "Epoch 64/94\n",
      "53/53 - 2s - 30ms/step - accuracy: 0.7854 - loss: 0.5749\n",
      "Epoch 65/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7791 - loss: 0.5932\n",
      "Epoch 66/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7830 - loss: 0.5811\n",
      "Epoch 67/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7837 - loss: 0.5872\n",
      "Epoch 68/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7835 - loss: 0.5797\n",
      "Epoch 69/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7858 - loss: 0.5773\n",
      "Epoch 70/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7890 - loss: 0.5699\n",
      "Epoch 71/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7863 - loss: 0.5732\n",
      "Epoch 72/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7850 - loss: 0.5728\n",
      "Epoch 73/94\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.7890 - loss: 0.5615\n",
      "Epoch 74/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7881 - loss: 0.5665\n",
      "Epoch 75/94\n",
      "53/53 - 1s - 24ms/step - accuracy: 0.7914 - loss: 0.5604\n",
      "Epoch 76/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7922 - loss: 0.5550\n",
      "Epoch 77/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7917 - loss: 0.5633\n",
      "Epoch 78/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7952 - loss: 0.5506\n",
      "Epoch 79/94\n",
      "53/53 - 1s - 27ms/step - accuracy: 0.7965 - loss: 0.5566\n",
      "Epoch 80/94\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.7954 - loss: 0.5483\n",
      "Epoch 81/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.7953 - loss: 0.5499\n",
      "Epoch 82/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.7968 - loss: 0.5456\n",
      "Epoch 83/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.7958 - loss: 0.5470\n",
      "Epoch 84/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.7975 - loss: 0.5444\n",
      "Epoch 85/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.7996 - loss: 0.5379\n",
      "Epoch 86/94\n",
      "53/53 - 1s - 15ms/step - accuracy: 0.8001 - loss: 0.5424\n",
      "Epoch 87/94\n",
      "53/53 - 2s - 29ms/step - accuracy: 0.8027 - loss: 0.5352\n",
      "Epoch 88/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.8022 - loss: 0.5323\n",
      "Epoch 89/94\n",
      "53/53 - 1s - 19ms/step - accuracy: 0.8022 - loss: 0.5334\n",
      "Epoch 90/94\n",
      "53/53 - 1s - 21ms/step - accuracy: 0.8009 - loss: 0.5355\n",
      "Epoch 91/94\n",
      "53/53 - 1s - 18ms/step - accuracy: 0.8040 - loss: 0.5358\n",
      "Epoch 92/94\n",
      "53/53 - 1s - 20ms/step - accuracy: 0.8029 - loss: 0.5314\n",
      "Epoch 93/94\n",
      "53/53 - 1s - 22ms/step - accuracy: 0.8094 - loss: 0.5163\n",
      "Epoch 94/94\n",
      "53/53 - 1s - 23ms/step - accuracy: 0.8073 - loss: 0.5187\n",
      "14/14 - 1s - 41ms/step\n",
      "Epoch 1/94\n",
      "Epoch 1/94\n",
      "Epoch 1/94\n",
      "Epoch 1/94\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.059    \u001b[39m | \u001b[39m261.6    \u001b[39m | \u001b[39m0.2898   \u001b[39m | \u001b[39m0.04837  \u001b[39m | \u001b[39m94.38    \u001b[39m | \u001b[39m2.616    \u001b[39m | \u001b[39m2.267    \u001b[39m | \u001b[39m2.743    \u001b[39m | \u001b[39m0.8056   \u001b[39m | \u001b[39m26.79    \u001b[39m | \u001b[39m0.8926   \u001b[39m | \u001b[39m3.775    \u001b[39m |\n",
      "Epoch 1/38\n",
      "16/16 - 3s - 216ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/38\n",
      "16/16 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/38\n",
      "16/16 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/38\n",
      "16/16 - 1s - 32ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/38\n",
      "16/16 - 0s - 25ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/38\n",
      "16/16 - 0s - 28ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/38\n",
      "16/16 - 0s - 25ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/38\n",
      "16/16 - 0s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/38\n",
      "16/16 - 0s - 27ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/38\n",
      "16/16 - 0s - 26ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 11/38\n",
      "16/16 - 0s - 28ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 12/38\n",
      "16/16 - 0s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 13/38\n",
      "16/16 - 0s - 29ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 14/38\n",
      "16/16 - 1s - 36ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 15/38\n",
      "16/16 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 16/38\n",
      "16/16 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 17/38\n",
      "16/16 - 1s - 48ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 18/38\n",
      "16/16 - 1s - 43ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 19/38\n",
      "16/16 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 20/38\n",
      "16/16 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 21/38\n",
      "16/16 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 22/38\n",
      "16/16 - 1s - 41ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 23/38\n",
      "16/16 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 24/38\n",
      "16/16 - 1s - 45ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 25/38\n",
      "16/16 - 1s - 47ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 26/38\n",
      "16/16 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 27/38\n",
      "16/16 - 1s - 34ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 28/38\n",
      "16/16 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 29/38\n",
      "16/16 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 30/38\n",
      "16/16 - 1s - 42ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 31/38\n",
      "16/16 - 1s - 40ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 32/38\n",
      "16/16 - 1s - 46ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 33/38\n",
      "16/16 - 1s - 39ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 34/38\n",
      "16/16 - 1s - 38ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 35/38\n",
      "16/16 - 1s - 48ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 36/38\n",
      "16/16 - 0s - 28ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 37/38\n",
      "16/16 - 0s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 38/38\n",
      "16/16 - 0s - 22ms/step - accuracy: 0.6440 - loss: nan\n",
      "4/4 - 0s - 106ms/step\n",
      "Epoch 1/38\n",
      "Epoch 1/38\n",
      "Epoch 1/38\n",
      "Epoch 1/38\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m7.267    \u001b[39m | \u001b[39m916.9    \u001b[39m | \u001b[39m0.318    \u001b[39m | \u001b[39m0.03302  \u001b[39m | \u001b[39m38.23    \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m2.636    \u001b[39m | \u001b[39m2.721    \u001b[39m | \u001b[39m0.01688  \u001b[39m | \u001b[39m55.97    \u001b[39m | \u001b[39m0.4174   \u001b[39m | \u001b[39m1.555    \u001b[39m |\n",
      "Epoch 1/62\n",
      "30/30 - 4s - 138ms/step - accuracy: 0.3797 - loss: 106.5350\n",
      "Epoch 2/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.3964 - loss: 88.7620\n",
      "Epoch 3/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.3961 - loss: 71.3707\n",
      "Epoch 4/62\n",
      "30/30 - 1s - 45ms/step - accuracy: 0.4411 - loss: 70.2504\n",
      "Epoch 5/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4114 - loss: 71.8927\n",
      "Epoch 6/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4335 - loss: 76.6570\n",
      "Epoch 7/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.4228 - loss: 74.9375\n",
      "Epoch 8/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4010 - loss: 72.7166\n",
      "Epoch 9/62\n",
      "30/30 - 1s - 41ms/step - accuracy: 0.4389 - loss: 71.7374\n",
      "Epoch 10/62\n",
      "30/30 - 1s - 46ms/step - accuracy: 0.4068 - loss: 67.8424\n",
      "Epoch 11/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4302 - loss: 72.3333\n",
      "Epoch 12/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.3966 - loss: 75.6539\n",
      "Epoch 13/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4367 - loss: 71.6141\n",
      "Epoch 14/62\n",
      "30/30 - 1s - 43ms/step - accuracy: 0.3967 - loss: 74.9834\n",
      "Epoch 15/62\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.4201 - loss: 73.0525\n",
      "Epoch 16/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4109 - loss: 77.4453\n",
      "Epoch 17/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4070 - loss: 74.3795\n",
      "Epoch 18/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4459 - loss: 66.7984\n",
      "Epoch 19/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.3878 - loss: 82.3758\n",
      "Epoch 20/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4533 - loss: 71.2298\n",
      "Epoch 21/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.3997 - loss: 73.0973\n",
      "Epoch 22/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4119 - loss: 74.4548\n",
      "Epoch 23/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4172 - loss: 74.7989\n",
      "Epoch 24/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.3822 - loss: 82.3206\n",
      "Epoch 25/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4642 - loss: 68.0504\n",
      "Epoch 26/62\n",
      "30/30 - 1s - 42ms/step - accuracy: 0.4042 - loss: 72.9192\n",
      "Epoch 27/62\n",
      "30/30 - 1s - 18ms/step - accuracy: 0.4418 - loss: 64.5282\n",
      "Epoch 28/62\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.4023 - loss: 74.8653\n",
      "Epoch 29/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4090 - loss: 75.1784\n",
      "Epoch 30/62\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.4357 - loss: 72.2049\n",
      "Epoch 31/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4148 - loss: 74.9446\n",
      "Epoch 32/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4159 - loss: 68.1362\n",
      "Epoch 33/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4082 - loss: 76.4112\n",
      "Epoch 34/62\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.4466 - loss: 72.1242\n",
      "Epoch 35/62\n",
      "30/30 - 1s - 27ms/step - accuracy: 0.4002 - loss: 73.6167\n",
      "Epoch 36/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4253 - loss: 72.9474\n",
      "Epoch 37/62\n",
      "30/30 - 1s - 29ms/step - accuracy: 0.4172 - loss: 67.7665\n",
      "Epoch 38/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4149 - loss: 71.4594\n",
      "Epoch 39/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.4145 - loss: 74.2668\n",
      "Epoch 40/62\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.4312 - loss: 75.0755\n",
      "Epoch 41/62\n",
      "30/30 - 1s - 30ms/step - accuracy: 0.4390 - loss: 65.0416\n",
      "Epoch 42/62\n",
      "30/30 - 1s - 43ms/step - accuracy: 0.4289 - loss: 73.3450\n",
      "Epoch 43/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.3886 - loss: 78.1364\n",
      "Epoch 44/62\n",
      "30/30 - 0s - 12ms/step - accuracy: 0.4291 - loss: 70.6267\n",
      "Epoch 45/62\n",
      "30/30 - 1s - 37ms/step - accuracy: 0.4360 - loss: 73.5027\n",
      "Epoch 46/62\n",
      "30/30 - 1s - 39ms/step - accuracy: 0.4165 - loss: 76.9208\n",
      "Epoch 47/62\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.3946 - loss: 80.0053\n",
      "Epoch 48/62\n",
      "30/30 - 1s - 28ms/step - accuracy: 0.3997 - loss: 71.8823\n",
      "Epoch 49/62\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.4192 - loss: 73.1038\n",
      "Epoch 50/62\n",
      "30/30 - 1s - 48ms/step - accuracy: 0.4197 - loss: 74.6998\n",
      "Epoch 51/62\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.4369 - loss: 73.6143\n",
      "Epoch 52/62\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.4259 - loss: 67.3567\n",
      "Epoch 53/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.4152 - loss: 70.1134\n",
      "Epoch 54/62\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.4241 - loss: 76.1063\n",
      "Epoch 55/62\n",
      "30/30 - 1s - 22ms/step - accuracy: 0.4209 - loss: 70.5816\n",
      "Epoch 56/62\n",
      "30/30 - 1s - 21ms/step - accuracy: 0.3950 - loss: 76.9771\n",
      "Epoch 57/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.4169 - loss: 73.7924\n",
      "Epoch 58/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.4260 - loss: 70.8095\n",
      "Epoch 59/62\n",
      "30/30 - 1s - 25ms/step - accuracy: 0.4009 - loss: 72.4433\n",
      "Epoch 60/62\n",
      "30/30 - 1s - 23ms/step - accuracy: 0.4414 - loss: 77.9358\n",
      "Epoch 61/62\n",
      "30/30 - 1s - 24ms/step - accuracy: 0.4184 - loss: 72.6126\n",
      "Epoch 62/62\n",
      "30/30 - 1s - 17ms/step - accuracy: 0.4139 - loss: 68.9580\n",
      "8/8 - 0s - 59ms/step\n",
      "Epoch 1/62\n",
      "Epoch 1/62\n",
      "Epoch 1/62\n",
      "Epoch 1/62\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m1.079    \u001b[39m | \u001b[39m470.1    \u001b[39m | \u001b[39m0.9429   \u001b[39m | \u001b[39m0.09696  \u001b[39m | \u001b[39m61.5     \u001b[39m | \u001b[39m2.406    \u001b[39m | \u001b[39m1.727    \u001b[39m | \u001b[39m2.944    \u001b[39m | \u001b[39m0.9628   \u001b[39m | \u001b[39m32.66    \u001b[39m | \u001b[39m0.4972   \u001b[39m | \u001b[39m2.106    \u001b[39m |\n",
      "Epoch 1/24\n",
      "60/60 - 5s - 80ms/step - accuracy: 0.4366 - loss: 33.7466\n",
      "Epoch 2/24\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.4838 - loss: 21.6755\n",
      "Epoch 3/24\n",
      "60/60 - 3s - 47ms/step - accuracy: 0.4870 - loss: 23.8149\n",
      "Epoch 4/24\n",
      "60/60 - 1s - 25ms/step - accuracy: 0.5050 - loss: 18.8344\n",
      "Epoch 5/24\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.4950 - loss: 22.3057\n",
      "Epoch 6/24\n",
      "60/60 - 2s - 30ms/step - accuracy: 0.5188 - loss: 18.8050\n",
      "Epoch 7/24\n",
      "60/60 - 2s - 30ms/step - accuracy: 0.5125 - loss: 18.9444\n",
      "Epoch 8/24\n",
      "60/60 - 1s - 20ms/step - accuracy: 0.5170 - loss: 19.1879\n",
      "Epoch 9/24\n",
      "60/60 - 2s - 31ms/step - accuracy: 0.5293 - loss: 18.4574\n",
      "Epoch 10/24\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.5247 - loss: 18.2966\n",
      "Epoch 11/24\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.5095 - loss: 19.7115\n",
      "Epoch 12/24\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.5190 - loss: 18.9855\n",
      "Epoch 13/24\n",
      "60/60 - 2s - 29ms/step - accuracy: 0.5327 - loss: 16.8822\n",
      "Epoch 14/24\n",
      "60/60 - 2s - 29ms/step - accuracy: 0.5285 - loss: 17.7869\n",
      "Epoch 15/24\n",
      "60/60 - 3s - 42ms/step - accuracy: 0.5034 - loss: 22.0424\n",
      "Epoch 16/24\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.5179 - loss: 19.5527\n",
      "Epoch 17/24\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.5181 - loss: 19.8608\n",
      "Epoch 18/24\n",
      "60/60 - 1s - 24ms/step - accuracy: 0.5088 - loss: 21.3838\n",
      "Epoch 19/24\n",
      "60/60 - 1s - 23ms/step - accuracy: 0.5362 - loss: 16.7043\n",
      "Epoch 20/24\n",
      "60/60 - 2s - 29ms/step - accuracy: 0.5343 - loss: 16.4175\n",
      "Epoch 21/24\n",
      "60/60 - 2s - 27ms/step - accuracy: 0.5159 - loss: 20.4852\n",
      "Epoch 22/24\n",
      "60/60 - 2s - 28ms/step - accuracy: 0.5244 - loss: 19.4443\n",
      "Epoch 23/24\n",
      "60/60 - 3s - 43ms/step - accuracy: 0.5306 - loss: 17.6803\n",
      "Epoch 24/24\n",
      "60/60 - 2s - 26ms/step - accuracy: 0.5241 - loss: 17.9576\n",
      "15/15 - 1s - 37ms/step\n",
      "Epoch 1/24\n",
      "Epoch 1/24\n",
      "Epoch 1/24\n",
      "Epoch 1/24\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.564    \u001b[39m | \u001b[39m229.5    \u001b[39m | \u001b[39m0.6096   \u001b[39m | \u001b[39m0.1508   \u001b[39m | \u001b[39m24.12    \u001b[39m | \u001b[39m1.557    \u001b[39m | \u001b[39m2.817    \u001b[39m | \u001b[39m1.479    \u001b[39m | \u001b[39m0.1534   \u001b[39m | \u001b[39m54.05    \u001b[39m | \u001b[39m0.9857   \u001b[39m | \u001b[39m1.694    \u001b[39m |\n",
      "Epoch 1/49\n",
      "18/18 - 5s - 296ms/step - accuracy: 0.4183 - loss: 3573.3618\n",
      "Epoch 2/49\n",
      "18/18 - 1s - 47ms/step - accuracy: 0.4853 - loss: 99.4716\n",
      "Epoch 3/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.5032 - loss: 49.5414\n",
      "Epoch 4/49\n",
      "18/18 - 1s - 53ms/step - accuracy: 0.5558 - loss: 26.9229\n",
      "Epoch 5/49\n",
      "18/18 - 1s - 52ms/step - accuracy: 0.5273 - loss: 18.9732\n",
      "Epoch 6/49\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.5602 - loss: 9.0808\n",
      "Epoch 7/49\n",
      "18/18 - 1s - 39ms/step - accuracy: 0.5047 - loss: 11.8931\n",
      "Epoch 8/49\n",
      "18/18 - 1s - 42ms/step - accuracy: 0.5400 - loss: 8.3964\n",
      "Epoch 9/49\n",
      "18/18 - 1s - 40ms/step - accuracy: 0.5220 - loss: 8.6197\n",
      "Epoch 10/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.5218 - loss: 8.3682\n",
      "Epoch 11/49\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.5307 - loss: 6.9259\n",
      "Epoch 12/49\n",
      "18/18 - 1s - 39ms/step - accuracy: 0.5409 - loss: 6.4550\n",
      "Epoch 13/49\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.4990 - loss: 10.1444\n",
      "Epoch 14/49\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.5486 - loss: 15.5595\n",
      "Epoch 15/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.5303 - loss: 8.9641\n",
      "Epoch 16/49\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.5313 - loss: 6.1545\n",
      "Epoch 17/49\n",
      "18/18 - 1s - 45ms/step - accuracy: 0.4942 - loss: 8.7368\n",
      "Epoch 18/49\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.5507 - loss: 6.0972\n",
      "Epoch 19/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.5593 - loss: 4.8959\n",
      "Epoch 20/49\n",
      "18/18 - 1s - 47ms/step - accuracy: 0.5366 - loss: 4.6704\n",
      "Epoch 21/49\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.5318 - loss: 4.9530\n",
      "Epoch 22/49\n",
      "18/18 - 1s - 39ms/step - accuracy: 0.5579 - loss: 5.6898\n",
      "Epoch 23/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.5441 - loss: 4.8779\n",
      "Epoch 24/49\n",
      "18/18 - 1s - 42ms/step - accuracy: 0.5736 - loss: 4.8093\n",
      "Epoch 25/49\n",
      "18/18 - 1s - 49ms/step - accuracy: 0.5393 - loss: 4.8867\n",
      "Epoch 26/49\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.5622 - loss: 4.1846\n",
      "Epoch 27/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.5483 - loss: 3.1672\n",
      "Epoch 28/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.5445 - loss: 3.6913\n",
      "Epoch 29/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.5523 - loss: 3.2561\n",
      "Epoch 30/49\n",
      "18/18 - 1s - 56ms/step - accuracy: 0.5951 - loss: 2.7746\n",
      "Epoch 31/49\n",
      "18/18 - 1s - 53ms/step - accuracy: 0.6065 - loss: 2.3146\n",
      "Epoch 32/49\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.5821 - loss: 2.4744\n",
      "Epoch 33/49\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6194 - loss: 2.7365\n",
      "Epoch 34/49\n",
      "18/18 - 1s - 40ms/step - accuracy: 0.5929 - loss: 2.2214\n",
      "Epoch 35/49\n",
      "18/18 - 1s - 49ms/step - accuracy: 0.4236 - loss: 12.0537\n",
      "Epoch 36/49\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.5135 - loss: 14.2461\n",
      "Epoch 37/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.4651 - loss: 8.7775\n",
      "Epoch 38/49\n",
      "18/18 - 1s - 43ms/step - accuracy: 0.5601 - loss: 6.8102\n",
      "Epoch 39/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.5948 - loss: 6.2782\n",
      "Epoch 40/49\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.6440 - loss: 4.9176\n",
      "Epoch 41/49\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.6440 - loss: 4.2033\n",
      "Epoch 42/49\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.6088 - loss: 4.3580\n",
      "Epoch 43/49\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.5763 - loss: 7.2390\n",
      "Epoch 44/49\n",
      "18/18 - 1s - 47ms/step - accuracy: 0.5834 - loss: 7.6095\n",
      "Epoch 45/49\n",
      "18/18 - 1s - 45ms/step - accuracy: 0.6440 - loss: 6.7747\n",
      "Epoch 46/49\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.6165 - loss: 5.7764\n",
      "Epoch 47/49\n",
      "18/18 - 1s - 45ms/step - accuracy: 0.6440 - loss: 4.7768\n",
      "Epoch 48/49\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.6440 - loss: 4.8359\n",
      "Epoch 49/49\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.6440 - loss: 4.4065\n",
      "5/5 - 0s - 91ms/step\n",
      "Epoch 1/49\n",
      "Epoch 1/49\n",
      "Epoch 1/49\n",
      "Epoch 1/49\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m6.049    \u001b[39m | \u001b[39m809.3    \u001b[39m | \u001b[39m0.2376   \u001b[39m | \u001b[39m0.2185   \u001b[39m | \u001b[39m49.42    \u001b[39m | \u001b[39m2.265    \u001b[39m | \u001b[39m2.267    \u001b[39m | \u001b[39m2.072    \u001b[39m | \u001b[39m0.09939  \u001b[39m | \u001b[39m85.18    \u001b[39m | \u001b[39m0.3208   \u001b[39m | \u001b[39m1.306    \u001b[39m |\n",
      "Epoch 1/61\n",
      "21/21 - 5s - 216ms/step - accuracy: 0.5393 - loss: 761.6782\n",
      "Epoch 2/61\n",
      "21/21 - 1s - 66ms/step - accuracy: 0.6440 - loss: 1.3614\n",
      "Epoch 3/61\n",
      "21/21 - 1s - 60ms/step - accuracy: 0.6440 - loss: 1.1712\n",
      "Epoch 4/61\n",
      "21/21 - 1s - 35ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 5/61\n",
      "21/21 - 1s - 61ms/step - accuracy: 0.6440 - loss: 1.1636\n",
      "Epoch 6/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1629\n",
      "Epoch 7/61\n",
      "21/21 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1637\n",
      "Epoch 8/61\n",
      "21/21 - 1s - 41ms/step - accuracy: 0.6440 - loss: 1.1639\n",
      "Epoch 9/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1653\n",
      "Epoch 10/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1643\n",
      "Epoch 11/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1663\n",
      "Epoch 12/61\n",
      "21/21 - 1s - 27ms/step - accuracy: 0.6440 - loss: 1.1663\n",
      "Epoch 13/61\n",
      "21/21 - 0s - 20ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 14/61\n",
      "21/21 - 0s - 22ms/step - accuracy: 0.6440 - loss: 1.1692\n",
      "Epoch 15/61\n",
      "21/21 - 0s - 19ms/step - accuracy: 0.6440 - loss: 1.1662\n",
      "Epoch 16/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1641\n",
      "Epoch 17/61\n",
      "21/21 - 1s - 24ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 18/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1653\n",
      "Epoch 19/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1651\n",
      "Epoch 20/61\n",
      "21/21 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1665\n",
      "Epoch 21/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1651\n",
      "Epoch 22/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 23/61\n",
      "21/21 - 1s - 37ms/step - accuracy: 0.6440 - loss: 1.1679\n",
      "Epoch 24/61\n",
      "21/21 - 1s - 63ms/step - accuracy: 0.6440 - loss: 1.1682\n",
      "Epoch 25/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1667\n",
      "Epoch 26/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1662\n",
      "Epoch 27/61\n",
      "21/21 - 1s - 27ms/step - accuracy: 0.6440 - loss: 1.1683\n",
      "Epoch 28/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1675\n",
      "Epoch 29/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1685\n",
      "Epoch 30/61\n",
      "21/21 - 1s - 30ms/step - accuracy: 0.6440 - loss: 1.1656\n",
      "Epoch 31/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1666\n",
      "Epoch 32/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1649\n",
      "Epoch 33/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1739\n",
      "Epoch 34/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1684\n",
      "Epoch 35/61\n",
      "21/21 - 1s - 32ms/step - accuracy: 0.6440 - loss: 1.1682\n",
      "Epoch 36/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1694\n",
      "Epoch 37/61\n",
      "21/21 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1695\n",
      "Epoch 38/61\n",
      "21/21 - 1s - 25ms/step - accuracy: 0.6440 - loss: 1.1695\n",
      "Epoch 39/61\n",
      "21/21 - 1s - 30ms/step - accuracy: 0.6440 - loss: 1.1674\n",
      "Epoch 40/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1689\n",
      "Epoch 41/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1682\n",
      "Epoch 42/61\n",
      "21/21 - 1s - 32ms/step - accuracy: 0.6440 - loss: 1.1714\n",
      "Epoch 43/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1674\n",
      "Epoch 44/61\n",
      "21/21 - 1s - 35ms/step - accuracy: 0.6440 - loss: 1.1678\n",
      "Epoch 45/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1654\n",
      "Epoch 46/61\n",
      "21/21 - 1s - 26ms/step - accuracy: 0.6440 - loss: 1.1674\n",
      "Epoch 47/61\n",
      "21/21 - 1s - 29ms/step - accuracy: 0.6440 - loss: 1.1664\n",
      "Epoch 48/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1688\n",
      "Epoch 49/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1739\n",
      "Epoch 50/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1685\n",
      "Epoch 51/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1665\n",
      "Epoch 52/61\n",
      "21/21 - 1s - 32ms/step - accuracy: 0.6440 - loss: 1.1694\n",
      "Epoch 53/61\n",
      "21/21 - 1s - 28ms/step - accuracy: 0.6440 - loss: 1.1687\n",
      "Epoch 54/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1706\n",
      "Epoch 55/61\n",
      "21/21 - 1s - 27ms/step - accuracy: 0.6440 - loss: 1.1690\n",
      "Epoch 56/61\n",
      "21/21 - 1s - 31ms/step - accuracy: 0.6440 - loss: 1.1712\n",
      "Epoch 57/61\n",
      "21/21 - 1s - 29ms/step - accuracy: 0.6440 - loss: 1.1681\n",
      "Epoch 58/61\n",
      "21/21 - 1s - 33ms/step - accuracy: 0.6440 - loss: 1.1712\n",
      "Epoch 59/61\n",
      "21/21 - 1s - 32ms/step - accuracy: 0.6440 - loss: 1.1684\n",
      "Epoch 60/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1666\n",
      "Epoch 61/61\n",
      "21/21 - 1s - 34ms/step - accuracy: 0.6440 - loss: 1.1673\n",
      "6/6 - 0s - 54ms/step\n",
      "Epoch 1/61\n",
      "Epoch 1/61\n",
      "Epoch 1/61\n",
      "Epoch 1/61\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.367    \u001b[39m | \u001b[39m672.7    \u001b[39m | \u001b[39m0.6776   \u001b[39m | \u001b[39m0.004976 \u001b[39m | \u001b[39m60.97    \u001b[39m | \u001b[39m1.453    \u001b[39m | \u001b[39m2.29     \u001b[39m | \u001b[39m1.349    \u001b[39m | \u001b[39m0.694    \u001b[39m | \u001b[39m44.81    \u001b[39m | \u001b[39m0.9367   \u001b[39m | \u001b[39m0.9626   \u001b[39m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:308\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m#25\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m--> 310\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[0;32m    311\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:254\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mrandom_sample())\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Finding argmax of the acquisition function.\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m suggestion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquisition_function\u001b[38;5;241m.\u001b[39msuggest(gp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, target_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space, fit_gp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(suggestion)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\acquisition.py:414\u001b[0m, in \u001b[0;36mUpperConfidenceBound.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    409\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived constraints, but acquisition function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support constrained optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConstraintNotSupportedError(msg)\n\u001b[1;32m--> 414\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msuggest(\n\u001b[0;32m    415\u001b[0m     gp\u001b[38;5;241m=\u001b[39mgp, target_space\u001b[38;5;241m=\u001b[39mtarget_space, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b, fit_gp\u001b[38;5;241m=\u001b[39mfit_gp\n\u001b[0;32m    416\u001b[0m )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_exploration()\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_max\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\acquisition.py:127\u001b[0m, in \u001b[0;36mAcquisitionFunction.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_gp:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_gp(gp\u001b[38;5;241m=\u001b[39mgp, target_space\u001b[38;5;241m=\u001b[39mtarget_space)\n\u001b[0;32m    129\u001b[0m acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_acq(gp\u001b[38;5;241m=\u001b[39mgp, constraint\u001b[38;5;241m=\u001b[39mtarget_space\u001b[38;5;241m.\u001b[39mconstraint)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acq_min(acq, target_space\u001b[38;5;241m.\u001b[39mbounds, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\acquisition.py:81\u001b[0m, in \u001b[0;36mAcquisitionFunction._fit_gp\u001b[1;34m(self, gp, target_space)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     80\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m     gp\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_space\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         target_space\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1328\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1328\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1329\u001b[0m         y,\n\u001b[0;32m   1330\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1331\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1334\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1335\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1336\u001b[0m     )\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1065\u001b[0m         array,\n\u001b[0;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1069\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    124\u001b[0m     X,\n\u001b[0;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    130\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), #9\n",
    "    'optimizer':(0,7), #7\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), #(10, 50), #\n",
    "    'epochs':(20, 100),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) #25\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c5307c0-070d-4a1c-a2e6-1aa536478570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 961,\n",
       " 'dropout': 0.7319939418114051,\n",
       " 'dropout_rate': 0.17959754525911098,\n",
       " 'epochs': 32,\n",
       " 'kernel': 1.3119890406724053,\n",
       " 'layers1': 1,\n",
       " 'layers2': 3,\n",
       " 'learning_rate': 0.6051038616257767,\n",
       " 'neurons': 74,\n",
       " 'normalization': 0.020584494295802447,\n",
       " 'optimizer': <keras.src.optimizers.ftrl.Ftrl at 0x1caca658310>}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "             'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "             'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "             'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93879248-be11-498d-b547-0bad4b8363cb",
   "metadata": {},
   "source": [
    "### Running CNN with Optimized Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80dfa5d3-1f90-49c0-984d-d8a112d5f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model with optimized hyperparameters\n",
    "\n",
    "epochs = 32\n",
    "batch_size = 961\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "\n",
    "layers1 = 1\n",
    "layers2 = 2\n",
    "activation = 'softsign'\n",
    "kernel = int(round(1.3119890406724053))  # Rounded kernel size for Conv1D\n",
    "neurons = 74\n",
    "normalization = 0.020584494295802447\n",
    "dropout = 0.7319939418114051\n",
    "dropout_rate = 0.17959754525911098\n",
    "optimizer = Adadelta(learning_rate=0.6051038616257767)  # Instantiate RMSprop with learning rate\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6cc404a6-ea75-48ae-9e5a-5b4b0ac76b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_75\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_75\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_380 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_381 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_382 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">518</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_383 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,785</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         â”‚           \u001b[38;5;34m740\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_380 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         â”‚         \u001b[38;5;34m5,550\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_381 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         â”‚         \u001b[38;5;34m5,550\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_382 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         â”‚         \u001b[38;5;34m5,550\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_75 (\u001b[38;5;33mMaxPooling1D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m74\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_75 (\u001b[38;5;33mFlatten\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m518\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_383 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             â”‚         \u001b[38;5;34m7,785\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,175</span> (98.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,175\u001b[0m (98.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,175</span> (98.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,175\u001b[0m (98.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fab0616-cddf-47a6-94a4-2d271bd29f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the y_test set back into a one-hot configuration\n",
    "y_train_one_hot = to_categorical(y_train, num_classes = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "855d37f1-a011-4d3c-8db3-ff82f93a6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc2489f7-8018-41e7-be6b-6b7f06c2c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "08b0417e-8bbe-4123-84aa-399f47d195d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "18/18 - 4s - 214ms/step - accuracy: 0.5377 - loss: 1.7394\n",
      "Epoch 2/32\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.6487 - loss: 1.0928\n",
      "Epoch 3/32\n",
      "18/18 - 1s - 47ms/step - accuracy: 0.6560 - loss: 1.0315\n",
      "Epoch 4/32\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.6594 - loss: 0.9984\n",
      "Epoch 5/32\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.6642 - loss: 0.9774\n",
      "Epoch 6/32\n",
      "18/18 - 1s - 49ms/step - accuracy: 0.6588 - loss: 0.9645\n",
      "Epoch 7/32\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.6688 - loss: 0.9403\n",
      "Epoch 8/32\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.6742 - loss: 0.9314\n",
      "Epoch 9/32\n",
      "18/18 - 1s - 43ms/step - accuracy: 0.6805 - loss: 0.9133\n",
      "Epoch 10/32\n",
      "18/18 - 1s - 49ms/step - accuracy: 0.6988 - loss: 0.8787\n",
      "Epoch 11/32\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6968 - loss: 0.8718\n",
      "Epoch 12/32\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.7079 - loss: 0.8483\n",
      "Epoch 13/32\n",
      "18/18 - 1s - 49ms/step - accuracy: 0.7142 - loss: 0.8310\n",
      "Epoch 14/32\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.7313 - loss: 0.7963\n",
      "Epoch 15/32\n",
      "18/18 - 1s - 50ms/step - accuracy: 0.7312 - loss: 0.7912\n",
      "Epoch 16/32\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.7450 - loss: 0.7639\n",
      "Epoch 17/32\n",
      "18/18 - 1s - 51ms/step - accuracy: 0.7383 - loss: 0.7674\n",
      "Epoch 18/32\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.7526 - loss: 0.7376\n",
      "Epoch 19/32\n",
      "18/18 - 1s - 79ms/step - accuracy: 0.7495 - loss: 0.7361\n",
      "Epoch 20/32\n",
      "18/18 - 1s - 41ms/step - accuracy: 0.7490 - loss: 0.7330\n",
      "Epoch 21/32\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.7583 - loss: 0.7129\n",
      "Epoch 22/32\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.7528 - loss: 0.7188\n",
      "Epoch 23/32\n",
      "18/18 - 1s - 46ms/step - accuracy: 0.7570 - loss: 0.7115\n",
      "Epoch 24/32\n",
      "18/18 - 1s - 43ms/step - accuracy: 0.7596 - loss: 0.6932\n",
      "Epoch 25/32\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.7625 - loss: 0.6945\n",
      "Epoch 26/32\n",
      "18/18 - 1s - 42ms/step - accuracy: 0.7614 - loss: 0.6905\n",
      "Epoch 27/32\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.7650 - loss: 0.6839\n",
      "Epoch 28/32\n",
      "18/18 - 1s - 44ms/step - accuracy: 0.7614 - loss: 0.6856\n",
      "Epoch 29/32\n",
      "18/18 - 1s - 43ms/step - accuracy: 0.7689 - loss: 0.6688\n",
      "Epoch 30/32\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.7686 - loss: 0.6643\n",
      "Epoch 31/32\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.7667 - loss: 0.6695\n",
      "Epoch 32/32\n",
      "18/18 - 1s - 48ms/step - accuracy: 0.7742 - loss: 0.6489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1caa790b410>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_one_hot, batch_size = batch_size, epochs = epochs, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538a6f7-9b98-4337-b0f3-f5de581b2a31",
   "metadata": {},
   "source": [
    "### Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "862e84ce-5cdd-4d62-b8da-3c1d9217b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of stations names\n",
    "\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d2088eb7-150b-4eab-8d12-d7717d75bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cce23c83-dbd4-4999-b3a4-6b82818fad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba83bb6e-8627-4de1-a57a-14b75df49dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  HEATHROW  LJUBLJANA  MADRID\n",
      "True                                                                      \n",
      "BASEL        3382       184        11       8         0          1      96\n",
      "BELGRADE      339       722         4       5         1          0      21\n",
      "BUDAPEST       66        87        46       5         1          0       9\n",
      "DEBILT         36        16         8      18         1          1       2\n",
      "DUSSELDORF     19         5         1       3         0          0       1\n",
      "HEATHROW       37         7         5       2        11          0      20\n",
      "KASSEL          7         2         1       0         0          1       0\n",
      "LJUBLJANA      28        12         4       0         1          5      11\n",
      "MAASTRICHT      7         0         0       1         0          0       1\n",
      "MADRID        100        52         5       1         3          2     295\n",
      "MUNCHENB        6         2         0       0         0          0       0\n",
      "OSLO            0         1         0       1         1          0       2\n",
      "STOCKHOLM       0         4         0       0         0          0       0\n",
      "VALENTIA        1         0         0       0         0          0       0\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "print(confusion_matrix(y_test, y_pred, stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721186cd-4d59-4fdf-9d4d-6a24b3462e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
